[
  {
    "objectID": "transcription-protocol.html",
    "href": "transcription-protocol.html",
    "title": "Transcription Protocol",
    "section": "",
    "text": "This document explains the procedures for transcribing spoken dialog into textual formats, including the notation applied to encode idiosyncratic elements of conversationa speech.\nDerived from the transcription protocol applied for the E-CURATORS project.",
    "crumbs": [
      "Transcription Protocol"
    ]
  },
  {
    "objectID": "transcription-protocol.html#cleaning-audio",
    "href": "transcription-protocol.html#cleaning-audio",
    "title": "Transcription Protocol",
    "section": "Cleaning audio",
    "text": "Cleaning audio\nTo clean the audio:\n\nI select a clip that is representative of a single source of background noise, and then filter that wavelength throughout the entire audio file.\nAfter selecting the clip, go to Effect &gt;&gt; Noise Reduction and select Get Noise Profile, then press OK.\nClose the noise reduction menu, select the entire range of audio using the keyboard shortcut Command + A.\nThen go back to the noise reduction window (Effect &gt;&gt; Noise Reduction) to apply the filter based on the noise profile identified for the noisy clip.\nExport the modified audio file to the working directory (File &gt;&gt; Export &gt;&gt; Export as .WAV).\nUse ffmpeg to replace the dirty audio track with the clean one:\n\n  ffmpeg -i dirty.mp4 -i clean.wav -c:v copy -map 0:v:0 -map 1:a:0 clean.mp4",
    "crumbs": [
      "Transcription Protocol"
    ]
  },
  {
    "objectID": "qda-protocol.html",
    "href": "qda-protocol.html",
    "title": "Qualitaive Data Analysis Protocol",
    "section": "",
    "text": "This document outlines the analytical tools, methods and techniques.",
    "crumbs": [
      "QDA Protocol"
    ]
  },
  {
    "objectID": "posts/2024-12-09-hello-world/index.html",
    "href": "posts/2024-12-09-hello-world/index.html",
    "title": "Hello World!",
    "section": "",
    "text": "Welcome to the website for my CITF Postdoc! This will serve as a hub for documenting and sharing my work. I decided to do this as a way of managing and sharing always-updated drafts of research protocols with my supervisor and team members, but it is also generally useful for keeping my thoughts organized. I will also use this blog section to write my thoughts as the project progresses."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\nDec 18, 2024\n\n\nTechnical specs for this website\n\n\nwebsite\n\n\n\n\nDec 9, 2024\n\n\nReflection on first team meeting\n\n\nmeeting notes, general thoughts\n\n\n\n\nDec 9, 2024\n\n\nHello World!\n\n\nintroduction, website\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Blog"
    ]
  },
  {
    "objectID": "notes/maelstrom-readings.html",
    "href": "notes/maelstrom-readings.html",
    "title": "Maelstrom reading notes",
    "section": "",
    "text": "Initial overview of data harmonization procedures, using the Healthy Obesity Project (HOP) as an illustrative case.\nOutlines the technical apparatus, especially for DataShield, but also broadly describes the discursive process of arriving at a DataSchema that is both functional and flexible.\n\nThis description is quite broad and abstracy, seems somewhat ideal and aspirational.\n\nDescribes reliance on international standards, such as the International Labour Organization’s International Standard Classification of Occupations.\n\nIt seems like these are used as black boxes that encapsulate a series of tensions which epidemiologists are unconcerned with; in effect, they simplify the need for stretching the collaborative ties even further than they are already extended, they represent matters out of scope for deeper discursive engagement.\n\nIt is notable that they emphasize that it’s easy to set up and use DataShield and Maelstorm toolkits independently of university IT and that it can be run using RStudio installed on a basic laptop.\n\nMaybe look into the historical context (2013) and the evolving role of university IT in software selection.\n\nThe conclusion states that the HOP project was successful in its harmonization efforts, but does not go as far as to state that it produced meaningful findings as a result of harmonization.\n\nI may take some time to find and read studies that used these data to see what’s what.\nThis seems like the main one: https://doi.org/10.1186/1472-6823-14-9, but these other papers may or not not also be relevant:\n\nhttps://doi.org/10.1016/j.smhl.2021.100263\nhttps://doi.org/10.1007/s10654-014-9977-1\nhttps://doi.org/10.1530/EJE-14-0540\nhttps://doi.org/10.1007/S13679-020-00375-0\nhttps://doi.org/10.1093/eurpub/ckac061"
  },
  {
    "objectID": "notes/maelstrom-readings.html#doiron2013",
    "href": "notes/maelstrom-readings.html#doiron2013",
    "title": "Maelstrom reading notes",
    "section": "",
    "text": "Initial overview of data harmonization procedures, using the Healthy Obesity Project (HOP) as an illustrative case.\nOutlines the technical apparatus, especially for DataShield, but also broadly describes the discursive process of arriving at a DataSchema that is both functional and flexible.\n\nThis description is quite broad and abstracy, seems somewhat ideal and aspirational.\n\nDescribes reliance on international standards, such as the International Labour Organization’s International Standard Classification of Occupations.\n\nIt seems like these are used as black boxes that encapsulate a series of tensions which epidemiologists are unconcerned with; in effect, they simplify the need for stretching the collaborative ties even further than they are already extended, they represent matters out of scope for deeper discursive engagement.\n\nIt is notable that they emphasize that it’s easy to set up and use DataShield and Maelstorm toolkits independently of university IT and that it can be run using RStudio installed on a basic laptop.\n\nMaybe look into the historical context (2013) and the evolving role of university IT in software selection.\n\nThe conclusion states that the HOP project was successful in its harmonization efforts, but does not go as far as to state that it produced meaningful findings as a result of harmonization.\n\nI may take some time to find and read studies that used these data to see what’s what.\nThis seems like the main one: https://doi.org/10.1186/1472-6823-14-9, but these other papers may or not not also be relevant:\n\nhttps://doi.org/10.1016/j.smhl.2021.100263\nhttps://doi.org/10.1007/s10654-014-9977-1\nhttps://doi.org/10.1530/EJE-14-0540\nhttps://doi.org/10.1007/S13679-020-00375-0\nhttps://doi.org/10.1093/eurpub/ckac061"
  },
  {
    "objectID": "notes/maelstrom-readings.html#doiron2017",
    "href": "notes/maelstrom-readings.html#doiron2017",
    "title": "Maelstrom reading notes",
    "section": "Doiron et al. (2017)",
    "text": "Doiron et al. (2017)\n\nAn overview of the key software that facilitates data harmonization practices under Maelstrom, also briefly touched upon in Doiron et al. (2013).\nPage 1373 refers to graphical and programmatic interfaces and assumes certain roles and tasks associated with each.\nBriefly describes its use by the Canadian Longitudinal Study on Aging (CLSA), the Canadian Partnership for Tomorrow Project (CPTP) and InterConnect, primarily by describing the range and quantity of data that these systems manage in each case.\n\n\nOpal provides a centralized web-based data management system allowing study coordinators and data managers to securely import/export a variety of data types (e.g. text, nu merical, geolocation, images, videos) and formats (e.g. SPSS, CSV) using a point-and-click interface. Opal then converts, stores and displays these data under a standar dized model.\n\n\nMica is used to create websites and metadata portals for individual epidemiological studies or multi-study consor tia, with a specific focus on supporting observational co hort studies. The Mica application helps data custodians and study or network coordinators to efficiently organize and disseminate information about their studies and net works without significant technical effort."
  },
  {
    "objectID": "notes/maelstrom-readings.html#fortier2010",
    "href": "notes/maelstrom-readings.html#fortier2010",
    "title": "Maelstrom reading notes",
    "section": "Fortier et al. (2010)",
    "text": "Fortier et al. (2010)\n\nA very grandiose paper presenting the grand vision for DataSHaPER, which would eventually become Maelstrom.\n\nLots of co-authors!\n\nInvokes the pan-European EPIC project (European Prospective Investigation into Cancer and Nutrition), which faced numerous data synthesis challenges despite its proactive effort to coordinate work across numerous research centres.\n\n\nTwo complementary approaches may be adopted to support effective data synthesis. The first one principally targets ‘what’ is to be synthesized, whereas the other one focuses on ‘how’ to collect the required information. Thus: (i) core sets of information may be identified to serve as the foundation for a flexible approach to harmonization; or (ii) standard collection devices (questionnaires and stand ard operating procedures) may be suggested as a required basis for collection of information.\n\n\nDataSHaPER is an acronym for DataSchema and Harmonization Platform for Epidemiological Research.\n\n\nIn an ideal world, information would be ‘prospectively harmonized’: emerging studies would make use, where possible, of harmonized questionnaires and standard operating procedures. This enhances the potential for future pooling but entails significant challenges —- ahead of time -— in developing and agree ing to common assessment protocols. However, at the same time, it is important to increase the utility of existing studies by ‘retrospectively harmonizing’ data that have already been collected, to optimize the subset of information that may legitimately be pooled. Here, the quantity and quality of infor mation that can be pooled is limited by the heterogeneity intrinsic to the pre-existing differences in study design and conduct.\n\nCompares prospective and retrospective harmonizatiom, with the former being presented as ideal, and the latter being a pragmatic reconciliation in acknowledgement that the former is essentially impossible to achieve.\n\nDataSHaPER is strikingly similar to OCHRE:\n\nXML-based data structures\nGenesis of a generic and ultimately optional base-level schema that illustrates the kind of data that the data structure may hold in ways that are immediately recognizable to all practitioners (at OCHRE it was associations between contexts and finds)\nSeparate harmonization platform where users can edit and manipulate records and associations between them\n\n\n\nThe question ‘What would constitute the ultimate proof of success or failure of the DataSHaPER approach’ needs to be addressed. Such proof will necessarily accumulate over time, and will involve two fundamental elements: (i) ratification of the basic DataSHaPER approach; and (ii) confirmation of the quality of each individual DataSHaPER as they are developed and/or extended. An important indication of the former would be provided by the widespread use of our tools. However, the ultimate proof of principle will necessarily be based on the generation of replicable scientific findings by researchers using the approach. But, for such evidence to accumulate it will be essential to assure the quality of each individual DataSHaPER. Even if the fundamental approach is sound, its success will depend critically on how individual DataSHaPERs are constructed and used. It seems likely that if consistency and quality are to be assured in the global development of the approach, it will be necessary for new DataSHaPERs to be formally endorsed by a central advisory team."
  },
  {
    "objectID": "notes/maelstrom-readings.html#fortier2011",
    "href": "notes/maelstrom-readings.html#fortier2011",
    "title": "Maelstrom reading notes",
    "section": "Fortier et al. (2011)",
    "text": "Fortier et al. (2011)\nThis paper responds to Hamilton et al. (2011), which presents an effort to devise a standardized nomenclature. The response is basically to advocate for a more flexible approach, rather than a stringent one promoted by Hamilton et al. (2011). It draws extensively from concepts published in the foundational paper by Fortier et al. (2010).\n\nTwo complementary approaches to harmonization may be adopted to support effective data synthesis or comparison across studies. The first approach makes use of identical data collection tools and procedures as a basis for harmoni zation and synthesis. Here we refer to this as the ‘‘stringent’’ approach to harmonization. The second approach is con sidered ‘‘flexible’’ harmonization. Critically, the second ap proach does not demand the use of identical data collection tools and procedures for harmonization and synthesis. Rather, it has to be based on sound methodology to ensure inferential equivalence of the information to be harmonized. Here, standardization is considered equivalent to stringent harmonization. It should, however, be noted that the term standard is occasionally employed to refer to common con cepts or comparable classification schemes but does not necessarily involve the use of identical data collection tools and procedures (12, 13).\n\nThis directly parallels the distinction made in Fortier et al. (2010) between “ideal” prospective and more pragmatic retrospective approaches to data harmonization.\n\nSynthesis of data using a flexible harmonization approach may be either prospective or retrospective. To achieve flexible prospective harmonization, investigators from several studies will agree on a core set of variables (or measures), compatible sets of data collection tools, and standard operating procedures but will allow a certain level of flexibilit in the specific tools and procedures used in each study (16, 17). Retrospective harmonization targets synthesis of information already collected by existing legacy studies (15, 18, 19). As an illustrative example, using retrospective harmonization, researchers will define a core set of variables (e.g., body mass index, global level of physical activity) and, making use of formal pairing rules, assess the potential for each participating study to create each variable (15). The ability to retrospectively harmonize data from existing studies facilitates the rapid generation of new scientifi knowledge.\n\nI wonder why there is no example provided for prospective data harmonization. Is it because it is ideal and not realistic? I’d argue that it is simply what occurs within projects."
  },
  {
    "objectID": "notes/maelstrom-readings.html#fortier2017",
    "href": "notes/maelstrom-readings.html#fortier2017",
    "title": "Maelstrom reading notes",
    "section": "Fortier et al. (2017)",
    "text": "Fortier et al. (2017)\nExplicit statement regarding the rationale and presumed benefits of harmonization right in the first paragraph:\n\nThe rationales underpinning such an approach include ensuring: sufficient statistical power; more refined subgroup analysis; increased exposure hetero geneity; enhanced generalizability and a capacity to under take comparison, cross validation or replication across datasets. Integrative agendas also help maximizing the use of available data resources and increase cost-efficiency of research programmes.\n\n\nensuring sufficient statistical power\nmore refined subgroup analysis\nincreased exposure heterogeneity\nenhanced generalizability\na capacity to undertake comparison, cross validation or replication across datasets.\nmaximizing the use of available data resources\nincrease cost-efficiency of research programmes\n\nClearly defines harmonization and its benefits:\n\nEssentially, data harmonization achieves or improves comparability (inferential equivalence) of similar measures collected by separate studies.\n\nAdds an additional argument for retrospective harmonization on top of prior discussion of retrospective/prospective approaches (cf. Fortier et al. (2010); Fortier et al. (2011)):\n\nRepeating identical protocols is not necessarily viewed as providing evidence as strong as that obtained by exploring the same topic but using different designs and measures.\n\nAlso relates retrospective harmonization from systematic meta reviews. In fact, the paper basically responds to calls for more structured guidelines for data harmonization, similar to those that had been produced to support structured metareviews in the years prior to this publication. The authors identify several papers that have done similar guidelines or reports on harmonization practices, which they claim are too broad. Those papers include:\n\nRolland et al. (2015)\n\nhttps://doi.org/10.1093/aje/kwv133\n\nSchaap et al. (2011)\n\nhttps://doi.org/10.1186/1471-2474-12-272\n\nBennett et al. (2011)\n\nhttps://doi.org/10.1002/gepi.20564\n\nHohmann et al. (2012)\n\nThe paper applied a questionnaire among data harmonization initiatives. The findings indicate that procedures were more attentively follows during earlier stages, such as when matching and aligning available data with the project’s designated scope. However, procedures were less sound with regards to documenting procedures, validating the results of data processing, and dissemination strategy. There is a notable division between work that occurs before and after people actually begin handling the data, which indicates a tension between aspirational idealism and a reckoning with the practical challenges of reconciling data deriving from multiple sources.\n\nRespondents were asked to delineate the specific procedures or steps undertaken to generate the harmonized data requested. Sound procedures were generally described; however, the terminologies, sequence and technical and methodological approaches to these procedures varied considerably. Most of the procedures mentioned were related to defining the research questions, identifying and selecting the participating studies (generally not through a systematic approach), identifying the targeted variables to be generated and processing data into the harmonized variables. These procedures were reported by at least 75% of the respondents. On the other hand, few reported steps related to validation of the harmonized data (N=4; 11.8%), documentation of the harmonization process (N=5; 14.7%) and dissemination of the harmonized data outputs (N=2; 5.9%).\n\nThe paper summarizes some specific “potential pitfalls” reported by respondents to their survey:\n\nensuring timely access to data;\nhandling dissimilar restrictions and procedures related to individual participant data access;\nmanaging diversity across the rules for authorship and recognition of input from study-specific investigators;\nmobilizing sufficient time and resources to conduct the harmonization project;\ngathering information and guidance on harmonization approaches, resources and techniques;\nobtaining comprehensive and coherent information on study-specific designs, standard operating procedures, data collection devices, data format and data content;\nunderstanding content and quality of study-specific data;\ndefining the realistic, but scientifically acceptable, level of heterogeneity (or content equivalence) to be obtained;\ngenerating effective study-specific and harmonized datasets, infrastructures and computing capacities;\nprocessing data under a harmonized format taking into account diversity of: study designs and content, study population, synchronicity of measures (events measured at different point in time or at different intervals when repeated) etc;\nensuring proper documentation of the process and decisions undertaken throughout harmonization to ensure transparency and reproducibility of the harmonized datasets;\nmaintaining long-term capacities supporting dissemination of the harmonized datasets to users.\n\nIt’s not made clear how these responses were distributed among respondents.\nThe authors then identify several absolute essential requirements needed to achieve success:\n\nCollaborative framework: a collaborative environment needs to be implemented to ensure the success of any harmonization project. Investigators involved should be open to sharing information and knowledge, and investing time and resources to ensure the successful implementation of a data-sharing infrastructure and achievement of the harmonization process.\nExpert input: adequate input and oversight by experts should be ensured. Expertise is often necessary in: the scientific domain of interest (to ensure harmonized variables permit addressing the scientific question with minimal bias); data harmonization methods (to support achievement of the harmonization procedures); and ethics and law (to address data access and integration issues).\nValid data input: study-specific data should only be harmonized and integrated if the original data items collected by each study are of acceptable quality.\nValid data output: transparency and rigour should be maintained throughout the harmonization process to ensure validity and reproducibility of the harmonization results and to guarantee quality of data output. The common variables generated necessarily need to be of acceptable quality.\nRigorous documentation: publication of results generated making use of harmonized data must provide the information required to estimate the quality of the process and presence of potential bias. This includes a description of the: criteria used to select studies; process achieved to select and define variables to be harmonized; procedures used to process data; and characteristics of the study-specific and harmonized dataset(s) (e.g. attribute of the populations).\nRespect for stakeholders: all study-specific as well as network-specific ethical and legal components need to be respected. This includes respect of the rights, intellectual property interests and integrity of study participants, investigators and stakeholders.\n\nThe authors describe how they arrived at guidelines following the results of this study:\n\nA consensus approach was used to assemble information about pitfalls faced during the harmonization process, establish guiding principles and develop the guidelines. The iterative process (informed by workshops and case studies) permitted to refine and formalize the guide lines. The only substantive structural change to the initial version proposed was the addition of specific steps relating to the validation, and dissemination and archiving of harmonized outputs. These steps were felt essential to em phasize the critical nature of these particular issues.\n\nThe paper outlines a checklist of stages that data harmonization initiatives need to go through to produce ideal outcomes. For each task, they describe a scenario in which the task can be said to be complete, whhich resembles an ideal outcome. This is described in the paper, summarized in a table, and more comprehensively documented in the supplementary materials.\nAlso worth noting, this paper includes a list of harmonization initiatives that I may consult when selecting cases. I’m not quite sure how useful it will be since the findings don’t really break down the distribution of responses in any detail, but maybe the authors have done this analysis and not published it."
  },
  {
    "objectID": "notes/maelstrom-readings.html#bergeron2018",
    "href": "notes/maelstrom-readings.html#bergeron2018",
    "title": "Maelstrom reading notes",
    "section": "Bergeron et al. (2018)",
    "text": "Bergeron et al. (2018)\nThe authors reference the drive for efficiency as a motivating factor that drives open data:\n\nHowever, many cohort databases remain under-exploited. To address this issue and speed up discovery, it is essential to offer timely access to cohort data and samples.\n\nHowever the paper is actually about the need for better and more publicly accessible documentation about data.\nThe authors state that catalogues exist to promote discoverability of data and samples and to answer the data documentation needs of individual studies.\nThey draw attention to the importance of catalogues in research networks (analyzing data across studies), which establish portals that document “summary statistics on study subjects, such as the number of participants presenting specific characteristics (e.g. diseases or exposures)”.\nThe authors outline several challenges that inhibit or limit the potential value of catalogues:\n\nThe quality of a catalogue directly depends on the quality and comprehensiveness of the study-specific information documented. But, maintaining and providing access to understandable and comprehensive documentation to external users can be challenging for cohort investigators, and require resources not always available, particularly for the very small or long-established studies. In addition, the technical work required to build and maintain a catalogue is particularly demanding. For example, gathering comprehensive±and comparable –information on study designs necessitates the implementation of rigorous procedures and working in close collaboration with study investigators. Manual classification of variables is also a long and a tedious process prone to human error. Moreover, the information collected needs to be regularly revised to update metadata with new data collections. These challenges, among others, can lead to the creation of catalogues with partial or disparate information across studies, documenting limited subsets of variables (e.g. only information collected at baseline) or including only studies with data dictionaries available in a specific language or format.\n\nThey then state that implementing “rigorous standard operating procedures” as a way to resolve these concerns:\n\nHowever, to truly optimize usage of available data and leverage scientific discovery, implementation of high quality metadata catalogues is essential. It is thus important to establish rigorous standard operating procedures when developing a catalogue, obtain sufficient financial support to implement and maintain it overtime, and where possible, ensure compatibility with other existing catalogues."
  },
  {
    "objectID": "notes/maelstrom-readings.html#bergeron2021",
    "href": "notes/maelstrom-readings.html#bergeron2021",
    "title": "Maelstrom reading notes",
    "section": "Bergeron et al. (2021)",
    "text": "Bergeron et al. (2021)\nIdentifies several registries of relevant cohorts, but notes that they face challenges getting the data together. Namely, issues concerning institutional policies concerning data-sharing, lack of open access to cohort data and to documentation about the data, the data’s complexity which makes it difficult to harmonize across studies, and lack of access to funding, secure data environments, and specialized expertise and resources.\nThe Research Advancement through Cohort Cataloguing and Harmonization (ReACH) initiative was establihed in collaboration with Maelstrom to overcome some of these barriers in the context of Developmental Origins of Health and Disease (DOHaD) research.\nThe authors briefly summarize some projects that rely on ReACH data, and provide a more comprehensive table of ongoing and unpublished work.\nIn the supplementary materials, the authors also include an illustrative example specific tasks, decisisions and actions that one might got through when using ReACH data. It is a broad-level but fairly sober account of how one would navigate the catalogue and engage with collaborators."
  },
  {
    "objectID": "notes/maelstrom-readings.html#wey2021",
    "href": "notes/maelstrom-readings.html#wey2021",
    "title": "Maelstrom reading notes",
    "section": "Wey et al. (2021)",
    "text": "Wey et al. (2021)\nx"
  },
  {
    "objectID": "notes/maelstrom-readings.html#wey2024",
    "href": "notes/maelstrom-readings.html#wey2024",
    "title": "Maelstrom reading notes",
    "section": "Wey and Fortier (2024)",
    "text": "Wey and Fortier (2024)\nx"
  },
  {
    "objectID": "notes/maelstrom-readings.html#gaye2014",
    "href": "notes/maelstrom-readings.html#gaye2014",
    "title": "Maelstrom reading notes",
    "section": "Gaye et al. (2014)",
    "text": "Gaye et al. (2014)\nIntroduces DataShield.\nFrames DataShield as a technical fix to administrative problems:\n\nMany technical and policy measures can be enacted to render data sharing more secure from a governance per spective and less likely to result in loss of intellectual prop erty. For example, data owners might restrict data release to aggregate statistics alone, or may limit the number of variables that individual researchers might access for speci fied purposes. Alternatively, secure analysis centres, such ,10 ,11 as the ESRC Secure Data Service and SAIL represent major informatics infrastructures that can provide a safe haven for remote or local analysis/linkage of data from selected sources while preventing researchers from down loading the original data themselves. However, to comple ment pre-existing solutions to the important challenges now faced, the DataSHIELD consortium has developed a flexible new way to comprehensively analyse individual level data collected across several studies or sources while keeping the original data strictly secure. As a technology, DataSHIELD uses distributed computing and parallelized analysis to enable full joint analysis of individual-level data from several sources—e.g. research projects or health or administrative data—without the need for those data to move, or even be seen, outside the study where they usually .12 reside Crucially, because it does not require underpin ning by a major informatics infrastructure and because it is based on non-commercial open source software, it is both locally implementable and very cost effective.\n\nAdds a social/collaborative element to earlier arguments about the challenges inherent of prospective harmonization, highlighting a need for engagement with individual studies (either through direct or peripheral participation) to conduct research that was not initially planned for:\n\nUnfortunately, both [study-level metadata] SLMA and [individual-level metadata] ILMA present significant problems Because SLMA com bines analytical results (e.g. means, odds ratios, regression coefficients) produced ahead of time by the contributing studies, it can be very inflexible: only the pre-planned analyses undertaken by all the studies can be converted into joint results across all studies combined. Any additional analyses must be requested post hoc. This hinders exploratory analysis for example the investigation of sub-groups, or interactions between key variables.\n\nProvides a detailed overview of how DataShield was implemented for HOP (Healthy Obesity Project), including the code used to generate specific figures and analyses. Hoever it does not really describe or reflect upon the processes through which the code was developed.\nThe authors highlight the fact that certain analytical approaches are not possible using DataShield, especially analysis that visualize individual data points. It’s unclear how they enforce this, or whether it’s an implicit limitation based on the data that DataShield participants provide.\n\nBecause in DataSHIELD potentially disclosive com mands are not allowed, some analyses that are possible in standard R are not enabled. In essence, there are two classes of limitation on potential DataSHIELD functional ity: (i) absolute limitations which require an analysis that can only be undertaken by enabling one of the functional ities (e.g. visualizing individual data points) that is explicitly blocked as a fundamental element of the DataSHIELD philosophy. For example, this would be the case for a standard scatter plot. Such limitations can never be circumvented and so alternatives (e.g. contour and heat map plots) are enabled which convey similar information but without disclosing individual data points; (ii) current limitations which are functions or models that we believe are implementable but we have not, as yet, under taken or completed the development work required. As examples, these latter include generalized linear mixed model (including multi-level modelling) and Cox regression.\n\nThe authors list numerous other limitations and challenges. Some have to do with what kinds of data DataShield can handle (something about horizontal and vertical that I do not yet fully understand). Other challenges include the need for data to be harmonized, and having to deal with governance concerns.\nNotably, the first challenge mentioned seems to contradict the statement earlier on (and made by Doiron et al. (2013)) that this is relatively easy to set up. The authors acknowledge the fact that coding for analysis using DataShield has a steep learning curve and requires some pre-planning to enable results from satellite computers to be properly combined. Their mitigation is to black-box these concerns by implementing simpler client-side functions that mask the more complex behaviours (and presumably translate error messages in ways that users can understand and act to resolve!).\n\nDespite its potential utility, implementation of DataSHIELD involves significant challenges. First, although set-up is fundamentally straightforward, application involves a relatively steep learning curve because the command structure is complex: it demands specification of the analysis to be undertaken, the studies to use and how to combine the results. In mitigation, most complex serverside functions are now called using simpler client-side functions and we are working on a menu-driven implementation.\n\nAlso interesting that they note how there may be unanticipated problems, either accidental or malicious, and their way of mitigating against this is to log all commands:\n\nFifth, despite the care taken to set up DataSHIELD so that it works properly and is non-disclosive, it is possible that unanticipated prob lems (accidental or malicious) may arise. In order to iden tify, describe and rectify any errors or loopholes that emerge and in order to identify deliberate miscreants, all commands issued on the client server and enacted on each data server are permanently logged.\n\nThis is even more interesting in light of their continuous reference to “data.care”, which they do not address in depth, but which seems to have been a scandal involving unauthorized release of personal health data used in research.\nThe authors add an additional caveat concerning the need to ensure that the data are cleaned in advance.\n\nBut, to be pragmatic, many of the routinely collected healthcare and administra tive databases will have to undergo substantial evolution before their quality and consistency are such that they can directly be used in high-quality research without exten sive preparatory work. By its very nature, such preparation—which typically includes data cleaning and data harmonization—cannot usually be undertaken in DataSHIELD, because it involves investigating discrepan cies and/or extreme results in individual data subjects: the precise functionality that DataSHIELD is designed to block. Such work must therefore be undertaken ahead of time by the data generators themselves—and this is de manding of time, resources and expertise that—at present - many administrative data providers may well be unwilling and/or unable to provide. That said, if the widespread us ability of such data is viewed as being of high priority, the required resources could be forthcoming.\n\nThis corresponds with another limitation identified earlier, namely with regards to identifying duplicate individual records across jurisdictional boundaries (which involves assumptions regarding nationality and identify – one of those weird myths that programmers can’t seem to let go!):\n\nSo far DataSHIELD has been applied in settings where individual participants in different studies are from different countries or from different regions so it is unlikely that any one person will appear in more than one source. However, going forward, that cannot al ways be assumed. We have therefore been consider ing approaches to identify and correct this problem based on probabilistic record linkage. In the genetic setting 48 the BioPIN provides an alternative solution. Ongoing work is required.\n\nNote the last line of the prior block quote regarding data cleaning:\n\nThat said, if the widespread us ability of such data is viewed as being of high priority, the required resources could be forthcoming.\n\nThis seems like a thread worth tugging at!"
  },
  {
    "objectID": "notes/maelstrom-readings.html#wolfson2010",
    "href": "notes/maelstrom-readings.html#wolfson2010",
    "title": "Maelstrom reading notes",
    "section": "Wolfson et al. (2010)",
    "text": "Wolfson et al. (2010)\nx"
  },
  {
    "objectID": "notes/maelstrom-readings.html#doiron2013a",
    "href": "notes/maelstrom-readings.html#doiron2013a",
    "title": "Maelstrom reading notes",
    "section": "Doiron, Raina, and Fortier (2013)",
    "text": "Doiron, Raina, and Fortier (2013)\nThis paper summarizes what was discussed at a workshop bringing together stakeholders who would contribute to two large data harmonization initiatives: the Canadian Longitudinal Study on Aging (CLSA) and the Canadian Partnership for Tomorrow Project (CPTP). It is therefore representative of plans and challenges that were held at an early stage when collaborations were being established.\nThe authors identify series of reasons for linking data, which I summarize here:\n\nMaximizing potential of disparate information resources\n\n\nenriching study datasets with additional data not being collected directly from study par ticipants\noffer vital information on health outcomes of participants\nvalidate self-reported information\n\n\nDrawing maximum value from data produced from public expenditure\n\n\noffers a cost-effective means to maximize the use of existing publicly funded data collections\n\n\nDevelop interdisciplinary collaborative networks\n\n\nby combining a wide range of risk factors, disease endpoints, and relevant socio-economic and biological measurements at a population level, linkage lays the groundwork for multidisciplinary health-research initiatives, which allow the exploration of new hypotheses not foreseeable using independent datasets\n\n\nEstablish long-lasting infrastructure and instill a collaborative culture\n\n\nLast, a coordinated pan-Canadian cohort-to-administrative linked database would establish legacy research infrastructures that will better equip the next generation of researchers across the country\n\nThe authors use the term “data linkage”:\n\nData linkage is “the bringing together from two or more different sources, data that relates to the same individual, family, place or event”. When linking data at the individual level, a common identifier (or a combination of identifiers) such as a personal health number, date of birth, place of residence, or sex, is used to combine data related to the same person but found in separate databases. Data linkage has been used in a number of research fields but is an especially valuable tool for health research given the large amount of relevant information collected by institutions such as governments, hospitals, clinics, health authorities, and research groups that can then be matched to data collected directly from consenting individuals participating in health research.\n\nThis is distinct from harmonization in that it is not meant to combine data with similar scope and schematic structure, but rather to relate information collected under various domains so that they could be more easily queried in tandem. I imagine this as reminiscient of establishing links between tables in a relational database.\nThe authors identify the open-endedness of the linked data as a unique challenge, without elaborating on this point:\n\nCLSA/CPTP-to-AHD linkage also poses unique challenges in that, in contrast to more traditional requests to link data to answer one-off research questions, it aims to establish a rich data repository that will allow investigators to answer a multitude of research questions over time.\n\nThe workshop participants established a 5-point plan:\n\nbuild strong collaborative relationships between stakeholders involved in data sharing (e.g., researchers, data custodians, and privacy commissioners);\nidentify an entity which could provide overall leadership as well as individual “champions” within each province;\nfind adequate and long-term resources and funding;\nclarify data linkage and data-sharing models and develop a common framework within which the data linkage process takes place; and\ndevelop a pilot project making use of a limited number of linked variables from participating provinces\n\nThe second point, about identifying “champions”, is kind of interesting, and I’d like to know more about what qualities these people were expcted to have, their domains of expertise, their collaborative/soft or technical skills, and how this plays into access to funds and general governance structures\nNeed to look at Roos, Menec, and Currie (2004), which they cite in the conclusion, specifically with reference to the aspiration to develop “information rich environments”. Seems like it is a primary source for the background on linked data in Manitoba and Australia."
  },
  {
    "objectID": "interview-protocol.html",
    "href": "interview-protocol.html",
    "title": "Interview Protocol",
    "section": "",
    "text": "Note\n\n\n\nThis document is still a work in progress.",
    "crumbs": [
      "Interview Protocol"
    ]
  },
  {
    "objectID": "interview-protocol.html#interview-conditions",
    "href": "interview-protocol.html#interview-conditions",
    "title": "Interview Protocol",
    "section": "Interview conditions",
    "text": "Interview conditions\nInterviews may be held either in-person or through online vide-conference. Interviews will be held in quiet and comfortable environments, such as office spaces or conference rooms.",
    "crumbs": [
      "Interview Protocol"
    ]
  },
  {
    "objectID": "interview-protocol.html#interview-records",
    "href": "interview-protocol.html#interview-records",
    "title": "Interview Protocol",
    "section": "Interview records",
    "text": "Interview records\nI will record all in-person interviews using a SONY ICD-UX560 audio recorder to capture audio in the lossless 16 bit 44.1 kHz Linear PCM wav format, with additional audio filters to enhance playback during transcription, if necessary.\nI will also record in-person interview sessions using a GoPro Hero 4 Silver action camera, pending interviewees’ informed consent to be video recorded. Based on prior interviews with scientists about their research experiences, I found that interviewees like to show me, rather than merely tell me, about what they are working on and the means through which they engage with information systems. The action cameras may be leveraged to record spontaneous video records of these demonstrations and provide me with an additional rich data source for further analysis. Moreover, the action cameras provide an additional backup audio recording in case of data loss on the primary recording device.\nI will also record handwritten notes comprising descriptive accounts of activities and interactions when recording devices are switched off, as well as preliminary interpretations of observed behaviours and notes on things I plan to follow up on at a later time.",
    "crumbs": [
      "Interview Protocol"
    ]
  },
  {
    "objectID": "interview-protocol.html#interview-guide",
    "href": "interview-protocol.html#interview-guide",
    "title": "Interview Protocol",
    "section": "Interview guide",
    "text": "Interview guide\n\nParticipants’ goals and perspectives\nFollow a life-history method to better understand participants’ professional backgrounds and their roles within their projects. The goal is to obtain information about their paths, not the rehearsed origin story.\n\nTo start, can you please tell me a little bit about your background?\nWhat is the project?\nWhat is your role?\nHow did you find yourself in this role?\nHow has your previous experience prepared you for your role\n\n\n\nProjects’ missions, purposes, motivations\nKeep in mind that this section is about the project in general. Specific practices and procedures will be addressed in a subsequent phase of the interview.\n\nWhat are the project’s primary challenges?\nHow are you working to overcome them?\n\n\n\nWhat makes thos project unique?\nWhat is the project doing that no other similar project is doing?\n\nPrompts:\n\nWhat happened next?\nWho was that person?\nTell me more about that development or event.\n\n\n\nPractices, procedures, relationships\n\nWhat does your role entail?\nCan you provide a couple examples of things that you recently did in this capacity?\n\n\n\nWho else do you frequently rely on, and what are their roles?\nCan you describe what they do, and perhaps give a few examples drawn from their recent work?\n\nPrompts:\n\nPlease give me an example.\nDo you remember a specific time when you did this?\n\n\nMaintaining the project community\nFor those in charge of recruiting new partners and maintaining community support:\n\nPlease briefly describe the process through which you obtain new partners or users.\nCan you please recall a recent example?\n\n\n\nHow well do you know each partner?\nDid you know them before their involvement?\n\n\n\nWould you describe the project as a tight knit community, or more open-ended?\n\n\n\nHow do you communicate with partners and contributors?\nWhat kinds of media or platforms do you use, and are they targeted for specific purposes? i.e. email, newsletters, social media, skype, personal communication at conferences\n\n\n\nAre there particular people in each project who you communicate with more frequently than others?\nWho are they, and why are these the people who you connect with?\n\n\n\nWhat do you consider your role or responsibility vis-a-vis the development/growth of this community?\nHow do you foster the community’s development and growth?\nDo you consider these efforts to be effective?\n\n\n\nCurating data\nFor those who actually handle the data in a preparatory or curatorial way:\n\n\nUsing the data\nFor those who actually use the data:\n\n\n\nAbout the technical infrastructures\n\n\nAbout the administrative infrastructures\n\n\nRelationships with Maelstrom",
    "crumbs": [
      "Interview Protocol"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "data-sharing\nXXXX.\n\ndata-harmonization\nXXXX.\n\ndata-integration\nXXXX.\n\ncollaboration\nXXXX.\n\ndata-sharing initiative\nXXXX.\nCorresponds with the term “harmonization initiative” in Fortier et al. (2017).\ncatalogue\nXXXX.\nBergeron et al. (2018), Bergeron et al. (2021)\n\n\n\n\nReferences\n\nBergeron, Julie, Dany Doiron, Yannick Marcon, Vincent Ferretti, and Isabel Fortier. 2018. “Fostering Population-Based Cohort Data Discovery: The Maelstrom Research Cataloguing Toolkit.” PLOS ONE 13 (7): e0200926. https://doi.org/10.1371/journal.pone.0200926.\n\n\nBergeron, Julie, Rachel Massicotte, Stephanie Atkinson, Alan Bocking, William Fraser, Isabel Fortier, and the ReACH member cohorts’ principal investigators. 2021. “Cohort Profile: Research Advancement Through Cohort Cataloguing and Harmonization (ReACH).” International Journal of Epidemiology 50 (2): 396–97. https://doi.org/10.1093/ije/dyaa207.\n\n\nFortier, Isabel, Parminder Raina, Edwin R Van den Heuvel, Lauren E Griffith, Camille Craig, Matilda Saliba, Dany Doiron, et al. 2017. “Maelstrom Research Guidelines for Rigorous Retrospective Data Harmonization.” International Journal of Epidemiology 46 (1): 103–5. https://doi.org/10.1093/ije/dyw075.",
    "crumbs": [
      "Glossary"
    ]
  },
  {
    "objectID": "data-management.html",
    "href": "data-management.html",
    "title": "Data Management Plan",
    "section": "",
    "text": "Note\n\n\n\nThis document is still a work in progress.\nThis document describes the data that this research will produce and the procedures for curating data throughout the project.",
    "crumbs": [
      "Data Management"
    ]
  },
  {
    "objectID": "data-management.html#data-collection",
    "href": "data-management.html#data-collection",
    "title": "Data Management Plan",
    "section": "Data collection",
    "text": "Data collection\nInterviews generate audio, video and textual records. I primarily rely on a SONY ICD-UX560 audio recorder, which contains 4GB of internal storage supplemented with a 32GB microSD card.1 I record using the lossless 16bit 44.1 kHz Linear PCM wav format.\n1 See https://weloty.com/sony-icd-ux560-review and https://weloty.com/using-the-sony-icd-ux560-the-4-how-tos for more information on this audio recording device.With participants’ consent, I also record video using a GoPro Hero 4 Silver action camera equipped with a 64GB microSD card.\nI maintain typed notes before, during and after each interview, which I may edit and re-organize to enhance clarity.\nImmediately after each interview, I copy the data off the recording devices and onto a dedicated project drive. I organize and rename files using a semantic naming scheme and then mirror all files onto physical and a cloud-based backup drives.",
    "crumbs": [
      "Data Management"
    ]
  },
  {
    "objectID": "data-management.html#processing-data",
    "href": "data-management.html#processing-data",
    "title": "Data Management Plan",
    "section": "Processing data",
    "text": "Processing data\nI use FFmpeg and Audacity to cut, concatenate, and clean the audio and video files if necessary. I generate transcripts of audio recordings following the transcription protocol.",
    "crumbs": [
      "Data Management"
    ]
  },
  {
    "objectID": "data-management.html#storage-and-backups",
    "href": "data-management.html#storage-and-backups",
    "title": "Data Management Plan",
    "section": "Storage and backups",
    "text": "Storage and backups\nI keep all data on a dedicated portable solid state drive which serves as a working directory for all research activities. I mirror the contents of this drive onto an identical secondary backup drive and onto cloud storage administered by the CITF using rsync.\nI maintain this website where I share documentation that supports this project and reflect on the work as it progresses. It is hosted using GitHub Pages and is backed up using Dropbox, however no sensitive research data will pass through these services.",
    "crumbs": [
      "Data Management"
    ]
  },
  {
    "objectID": "data-management.html#publishing-and-archiving",
    "href": "data-management.html#publishing-and-archiving",
    "title": "Data Management Plan",
    "section": "Publishing and archiving",
    "text": "Publishing and archiving\nAfter my research is complete, I will make a concerted effort to document all the data I will have collected and generated and deposit them in a digital repository operated by a dedicated team of digital archivists certified to curate and preserve research data in perpetuity.",
    "crumbs": [
      "Data Management"
    ]
  },
  {
    "objectID": "case-selection.html",
    "href": "case-selection.html",
    "title": "Case Selection",
    "section": "",
    "text": "Note\n\n\n\nThis document is still a work in progress.",
    "crumbs": [
      "Case Selection"
    ]
  },
  {
    "objectID": "case-selection.html#case-study-research",
    "href": "case-selection.html#case-study-research",
    "title": "Case Selection",
    "section": "Case Study Research",
    "text": "Case Study Research\nIn case-study research, cases represent discrete instances of a phenomenon that inform the researcher about it. The cases are not the subjects of inquiry, and instead represent unique sets of circumstances that frame or contextualize the phenomenon of interest (Stake 2006: 4-7).\nCases usually share common reference to the overall research themes, but exhibit variations that enable a researcher to capture different outlooks or perspectives on matters of common concern. Drawing from multiple cases thus enables comprehensive coverage of a broad topic that no single case may cover on its own (Stake 2006: 23). In other words, cases are contexts that ascribe particular local flavours to the activities I trace, and which I must consider to account fully for the range of motivations, circumstances and affordances that back decisions to perform activities and to implement them in specific ways.\nMoreover, the power of case study research derives from identifying consistencies that relate cases to each other, while simultaneously highlighting how their unique and distinguishing facets contribute to their representativeness of the underlying phenomon. Case study research therefore plays on the tensions that challenge relationships among cases and the phenomenon that they are being called upon to represent (Ragin 1999: 1139-1140).\nIt should be noted that case study research limits my ability to define causal relationships or to derive findings that may be generalized across the whole field of epidemiology. This being said, case study research allows me to articulate the series of inter-woven factors that impact how epidedemiological researchers coordinate and participate in data-sharing initiatives, while explicitly accounting for and drawing from the unique and situational contexts that frame each case.",
    "crumbs": [
      "Case Selection"
    ]
  },
  {
    "objectID": "case-selection.html#key-factors",
    "href": "case-selection.html#key-factors",
    "title": "Case Selection",
    "section": "Key Factors",
    "text": "Key Factors\nTo reiterate, this project investigates the social and collaborative apparatus that scaffold data-sharing initiatives in epidemiology. Through analysis of data obtained through interviews with various relevant stakeholders attached to data-sharing initiatives, the project will ascertain the actions taken and challenges experienced to mediate the varied motivations, needs and values of those involved. In effect, the project aims to articulate the collaborative commitments that govern the constitution and maintenance of epidemiological information commons, and to relate these to technological, administrative and epistemic factors.\nIn other words, I aim to make certain under-appreciated social and collaborative commitments that underlie data-sharing initiatives more visible and to draw greater attention to certain sensibilities, attitudes, and apprehensions that are relevant to contemporary discourse on the nature of epidemiological data and ongoing development of information infrastructures designed to support data integration and re-use.\nHere I outline some key factors that will guide the selection of cases so as to ensure that the project meaningfully addressses its goals.\n\n1. Longevity\nInitiatives that have existed for different durations of time will have different capacity to reflect on their practices. Younger projects will not have had as much of a chance to produce any research outcomes, but may be valuable sources for insight on expectations. More established projects will be able to reflect on unexpected challenges they may have experienced.\nIt will be good to have at least one younger project representing an initiative still “in flux”, one or two “legacy” projects (no longer active), and one or two at intermediate stages (extracting data for meaningful analysis, expanding the initiative’s scope, etc).\n\n\n2. Community composition\nThe size and composition of the community, degree of familiarity among its members, and the mechanisms through which connections are managed constitute additional important factors to consider. Communication and decision-making may take different forms when teams are either smaller and locally-concentrated or larger and dispersed. Decision-making may also be significantly impacted by diffferent governance models and degrees of community participation. It would be interesting to identify how leaders are differentiated from other participants, norms and expectations for getting involved in leadership positions, and considerations that are made when making decisions that impact the community.\n\n\n3. Support structures\nData-sharing may be supported by diverse funding models or tech stacks to support the work, which may significantly impact how the work progresses. Comparing sources of support for data-sharing will help me to explore how data-sharing is either integrated into or supplemented as a distinct outgrowth of “normal” science.\nSpecifically, it will be interesting to compare the extent to which projects are left to cobble together their own data-sharing infrastucture, and how this impacts attitudes and norms regarding the curation and nature of research data. I wonder whether lack of government support fosters creative, entrepeneurial, experimental or community-led models, how funding is provided to supporting the development of collaborative research networks, and how these feed back into norms and attitudes regarding the independence of individual research projects and the formation of collectively-maintained information commons.1\n1 There is some precedent for this in the social sciences and humanities, which are fields that open science policies and infrastructures are not really designed to handle. This marginizaliation had contributed to experimentation with community-based governance models (as per the Radical Open Access Collective) and broader community involvement in policy decisions concerning how the rich diversity of social science and humanities data should be curated.I expect a tendency for cases to be supported by limited-term, federally-funded grants, though it might be worth exploring how supplementary funding provided by non-government agencies, including private firms (through MITACS, for instance) and philanthropic organizations (such as the Gates Foundation) impact the work. I would therefore like to included cases funded through these kinds of initiatives in this project.\n\n\n4. Disciplinary trends\nData-sharing is undoubtably impacted by attitudes concerning the nature of data and their roles in scientific knowledge production, and it is therefore necessary to account for different perspectives. Although I am still somewhat unfamiliar with the diversity of thought on such matters in epidemiology, I intuit that much of the open science movement is driven by rather positivist attitude. I would like to include cases that take on alternative approaches to science.\n\n\n5. Historical or contextual factors\nScience is beholden to political trends, which impact ability to obtain funding and collaborate accross borders (e.g. Brexit’s impact on trans-European funding, including initiatives to attract and retain talent). Moreover, certain events, such as the Covid-19 pandemic, trigger responses in the scientific community. Even if these events are not the focus of the research, they must still be accounted for due to their presumed impacts.\n\n\n6. Kinds of data\nThe nature of the data will surely impact how they are shared. In epidemiology specifically, there are ethical limitations on sharing precise patient records. This may be especially salient in studies focusing in health in Indiginous populations, which may involve additional consideration in contexts of data-sharing.2 Moreover, controls on data collection procedures, including limited or controlled scope or decisions to account for specific factors (such as race, which is prevalent in American datasets but largely ignored elsewhere) may significantly impact what can be done with them when integrated at scale.\n2 The Data Governance and Management Toolkit for Self-Governing Indigenous Governments https://indigenousdatatoolkit.ca may be helpful for exploring these concerns, but I am still looking for epidemiologically-oriented resources on such matters.",
    "crumbs": [
      "Case Selection"
    ]
  },
  {
    "objectID": "case-selection.html#selecting-cases",
    "href": "case-selection.html#selecting-cases",
    "title": "Case Selection",
    "section": "Selecting Cases",
    "text": "Selecting Cases\nSince a significant aspect of this work is to compare different approaches to data-sharing that have not yet been systematically articulated, it will be necessary to loosely define the parameters through which each case will be initially characterized. I will rely on structured consultations with the research community to make sense of the data-sharing landscape and select cases accordingly. By consulting with key stakeholders, I will arrive at a consensus about which cases are worth approaching while documenting the rationale behind these selections.\nThe consultation process is meant to ensure that case selection adheres to community will and reasoning, while also ensuring that cases are logistically feasible. I will therefore ask for input from leading members of epidemioligical data-sharing initiatives who are familiar with the goals of the this project, and who are involved with the Maelstrom Project which establishes logistical boundaries around the scope of the project.\n\nFixed cases\nMaelstrom will serve as a “fixed point” that limits the scope of the cases’ breadth, while also ensuring that participants (and myself) have a common frame of reference. Moreover, the practices and values that support Maelstrom’s operations have already been documented to a certain extent by its leaders (cf. Doiron et al. 2017; Fortier et al. 2017; Fortier et al. 2023; Bergeron et al. 2018), by its partners (cf. Doiron et al. 2013; Wey et al. 2021; Bergeron et al. 2021) and by scholars of scientific practice (cf. M. J. Murtagh et al. 2012; Demir and Murtagh 2013; Madeleine J. Murtagh et al. 2016; Tacconelli et al. 2022; Gedeborg et al. 2023). This prior work will serve as valuable resources supporting this project.\nAdditionally, the fact that all cases interact with Maelstrom for their technical infrastructure will greatly simplify the interviews by reducing the “overhead” of having to learn or be told about the technical systems, which may distract from the primary themes I seek to address during interviews.\nCITF will also serve as a fixed case. This is partly for logistical reqasons, since the grant is meant to support the CITF Databank, and this project will align with concurrent research on user experiences pertaining to CITF specifically. At the same time, CITF is relevant to the project’s objectives in its own right, and will contribute meaningful insight in comparison with other cases.",
    "crumbs": [
      "Case Selection"
    ]
  },
  {
    "objectID": "case-selection.html#logistical-constraints-and-sources-of-bias",
    "href": "case-selection.html#logistical-constraints-and-sources-of-bias",
    "title": "Case Selection",
    "section": "Logistical Constraints and Sources of Bias",
    "text": "Logistical Constraints and Sources of Bias\nAfter identifying potential cases, I will reach out to project leaders to invite them to participate. I will prepare a document outlining this project’s objectives and the roles that cases will play in the work. I will also set up a meeting prior to them deciding whether they would like to participate so I can ascertain whether they understand the project and to help determine who may serve as people who can sit for interviews (I expect to hold 12-15 interviews ranging between 60-90 minutes in duration).\nI may prioritize local connections, which provide favourable conditions for holding interviews (i.e., people are more willing to show things that can not be conveyed through a screen, and the pre- and post-interview phases provide meaningful insight). This may introduce bias in that I may obtain more in-depth and nuanced information from local initiatives than those occurring abroad. This can be mitigated by travelling to conduct interviews in person, however the costs of travel may introduce their own biases favouring cases that are easier to reach.",
    "crumbs": [
      "Case Selection"
    ]
  },
  {
    "objectID": "context.html",
    "href": "context.html",
    "title": "Context",
    "section": "",
    "text": "Zack’s bio and information about the CITF as institutional host.",
    "crumbs": [
      "Context"
    ]
  },
  {
    "objectID": "ethics-protocol.html",
    "href": "ethics-protocol.html",
    "title": "Ethics Protocol",
    "section": "",
    "text": "Note\n\n\n\nThis document is still a work in progress.\nProject Title: Articulating epidemiological data harmonization initiatives as practical and collaborative experiences\nPrincipal Investigator: Zachary Batist\nProtocol Number: 25-01-057\nSubmitted:\nApproved:",
    "crumbs": [
      "Ethics Protocol"
    ]
  },
  {
    "objectID": "ethics-protocol.html#recruitment-and-consent",
    "href": "ethics-protocol.html#recruitment-and-consent",
    "title": "Ethics Protocol",
    "section": "Recruitment and consent",
    "text": "Recruitment and consent\nWill this study involve recruitment of human study participants?\n\nYes\nNo\n\nHow are potential study participants identified and/or recruited to the study? Explain how potential participants are identified or introduced to the study, and who will recruit participants. Will the investigator/s require any special permissions or access to the target population e.g. clinic access, patient registries or records, mailing lists, community access?\nThrough consultation with key community stakeholders, the principal investigator will devise a list of prospective projects to serve as cases.1 The principal investigator will then write to the leaders of these projects inviting them to participate in the study. These invitations to project leaders will explain the project’s purpose and scope, and will encourage the recipient to reply with any questions or concerns they may have. If they accept the invitation, the principal investigator will then work with project leaders to devise a list of individuals who may serve as interview candidates based on their roles in the project. The principal investigator will be clear with project leaders that they should not pressure those who work for them to participate in the study, and that individuals’ participation should be treated as separate from their regular duties; if project leaders cannot or will not abide by this condition, their project will be rejected as a prospective case. The principal investigator will then write to the recommended individuals to introduce the study and its objectives and to invite them to participate as research subjects.\n1 See the case selection protocol for further details.Describe the consent process. If alternate processes for seeking consent are planned (e.g. verbal, online, waiver), please provide a rationale and outline the procedure of obtaining and documenting consent and/or assent, where applicable.\nOnce individuals express their interest in participating, participants will provided with an informed consent document that outlines in more detail the goals of the study, the roles of the participant, how they will be recorded, how data pertaining to them will be retained, and the potential risks and benefits pertaining to their involvement. This document will also describe how participants’ personally identifiable information will be managed and used. Participants will be asked to read and sign the document in order to obtain written informed consent. At the start of each interview the researcher will reiterate participants’ rights and ask them to orally reaffirm their consent before proceeding.\nIs there a relationship between the study participants and the person obtaining consent and/or the principal investigator/s?\n\nYes\nNo\n\nIf yes, please explain the nature of the relationship, and outline the steps that will be taken to avoid the perception of undue influence.\nOne project that serves as a case in this research is the Covid-19 Immunity Task Force (CITF), which the principal investigator currently serve as postdoctoral researcher. Some of the participants will therefore be his colleagues; the interviews will remain structured and limited in scope, and will not touch on matters relating to other aspects of their work.\nThe principal investigator will consult with David Buckeridge, who leads the CITF, as one key community stakeholder to help devise a shortlist of projects that may serve as prospective cases.",
    "crumbs": [
      "Ethics Protocol"
    ]
  },
  {
    "objectID": "ethics-protocol.html#risk-benefit-assessment",
    "href": "ethics-protocol.html#risk-benefit-assessment",
    "title": "Ethics Protocol",
    "section": "Risk-benefit assessment",
    "text": "Risk-benefit assessment\nDescribe the foreseeable risks to study participants. What risks are attributable to the research, including cumulative risks? Which risks are participants normally exposed to in the course of their clinical care or in their daily activities as they relate to the research questions/objectives?\nParticipation in this study does not involve any physical, psychological or legal risks. However, the principal investigator will be asking participants to share detailed information about their work practices and work relationships, and public association with their responses may potentially disrupt or complicate their professional reputations. To mitigate against this potential harm, the principal investigator will give participants the option to render their responses confidential.\nWhat procedures are in place to monitor and assess participant safety for the duration of the study?\nPrior to each interview, and as part of the procedure for obtaining informed consent, participants will be asked about whether they want to render their responses confidential. Immediately after each interview, participants will be given an additional opportunity to reflect on their responses, and will be prompted to either confirm or alter their decision regarding whether or not to maintain confidentiality. Furthermore, for participants who have not requested that their responses be treated as confidential immediately before and after the interview, a follow-up email will be sent one week after the interview to reiterate the option to render their responses confidential.\nDescribe the potential benefits of the study for: (1) the study participants; (2) the population under investigation, and (3) the field of research.\nThis study contributes to the development of better epidemiological data-sharing infrastructures by articulating social, collaborative and discursive aspects of data harmonization, and how these factors relate to, overlap with or conflict with technical, institutional and epistemic factors. By explicitly framing data harmonization as a social and collaborative activity, we may devise more effective data-sharing infrastructures that better support the contextualization of data and enhance their value in contexts of data reuse. This work therefore poses new ways to document how epidemiologists mobilize distributed records in the constitution of synthetic knowledge and helps develop practical solutions that enable greater reflexivity. Additionally, this study may directly benefit participants by framing the experiences they address during interviews in ways that they might not have otherwise considered, thereby encouraging greater reflexivity in their own work.",
    "crumbs": [
      "Ethics Protocol"
    ]
  },
  {
    "objectID": "ethics-protocol.html#privacy-and-confidentiality",
    "href": "ethics-protocol.html#privacy-and-confidentiality",
    "title": "Ethics Protocol",
    "section": "Privacy and confidentiality",
    "text": "Privacy and confidentiality\nPlease describe the measures in place for meeting confidentiality obligations. How is information and data safeguarded for the full cycle of the study: i.e. during its collection, use, dissemination, retention, and/or disposal?\nThe specific circumstances that frame each case are significant factors that will shape the findings, and the study will benefit from participants’ consent to associate their identities with their interview responses. However, they may choose to render their interview responses confidential while maintaining their role a research participant. Participants may change their decision regarding whether or not to associate their identities with their interview responses up to one week after the interview, at which point the principal investigator will begin transcribing and analyzing the records pertaining to the interview. Participants will be reminded about this option immediately after the interview and one week following the interview via email.\nThe study engages with a relatively small community, and there is minimal social risk that others may be able to determine the identities of those whose research practices and professional relationships are being documented, even if their responses are rendered confidential. To address this issue, if any single participant from a case decides to render their responses confidential, the responses of all participants pertaining to that case will be rendered confidential as well, and the identify of the project that serves as the case will be obfuscated too.\nIn situations whereby a participant decides to render their responses confidential, or has their responses rendered confidential due to another member of their case deciding to do so, only the principal investigator will have access to records containing un-obfuscated information that may identify them. These un-obfuscated records, which may include audio and video records of interview sessions, as well as unedited transcripts and textual notes containing information that may reveal the participants’ identities, will be kept in secure and encrypted media, and destroyed within five years of concluding the study, which provides sufficient time to revisit the data and produce additional research outputs. However, edited transcripts scrubbed of all information that may identify research participants may be kept, published and archived. If participants consent to maintaining association between their responses and their identities, un-obfuscated records and transcripts may be kept, published and archived.\nThe study is committed to adhering to fundamental data security practices, including those specified in McGill University’s Cloud Directive which regulates the curation of sensitive research data. Physical records will be kept in a locked drawer in secure workspaces, either at McGill University’s School of Public and Global Health or at the principal researcher’s home office. Digital records will be stored on encrypted and password-protected drives.2\n2 Refer to the data management plan for further details on how information pertaining to this project will be collected, curated and shared.If a contracted cloud/storage service provider or online survey tool is used, provide information on the service provider’s security and privacy policy, location of its servers, data ownership, and what happens to the stored data after the contract is terminated. For more information, please consult the University’s directive.\nThe study uses file-sharing software hosted by the Covid-19 Immunity Task Force at McGill University’s School of Public and Global Health to backup all files maintained for this study. These backups will include files containing information that might reveal participants’ identities. The software used to manage these backups is managed by McGill University and has been approved for storing sensitive research data by the Cloud Directive.\nThe study maintains a website where the principal investigator shares documentation that supports the study and reflects on the work as it progresses. This is hosted using GitHub Pages and is backed up using Dropbox. The website exists to document the research practices, and no sensitive research data will pass through these services.\nPlease explain any reasonable and foreseeable disclosure requirements (e.g. disclosure to third parties such as government agencies or departments, community partners in research, personnel from an agency that monitors research, research sponsor, the REB/IRB, or regulatory agencies).\nNo disclosure requirements are foreseen.\nIf there are plans for retaining participant and/or study data for future use, please describe the context for its use, requirements for potentially re-contacting study participants and consent, and how the data will be stored and maintained for the long term.\nResearch data will be published in compliance with ethical standards for sharing open social science research data. Records that contain personally-identifying information pertaining to participants who have requested that their responses be rendered confidential and to those who have had their responses rendered confidential due to another member of their case deciding to do so will not be published.\nThe database containing codings, memos and trends deriving from qualitative data analysis will be published only after being scrubbed of all personally-identifying information pertaining to participants who have requested that their responses be rendered confidential and to those who have had their responses rendered confidential due to another member of their case deciding to do so.\nThe principal investigator may follow up with the leaders of the data-sharing initiatives that serve as cases for this project to share the results with them and to present them with constructive feedback deriving from the study’s findings. The principal investigator may also invite select participants to collaborate on a position paper advocating for reforms based on the project’s findings.\nSecondary use of data studies: if the study involves data linkage, please describe the data that will be linked and the likelihood that identifiable information will be created through the linkage.\nThis project does not rely on data deriving from other studies. The data may be reused in related work being undertaken under the same grant and by those who access the openly accessible data after they are published.",
    "crumbs": [
      "Ethics Protocol"
    ]
  },
  {
    "objectID": "ethics-protocol.html#managing-conflicts-of-interest",
    "href": "ethics-protocol.html#managing-conflicts-of-interest",
    "title": "Ethics Protocol",
    "section": "Managing conflicts of interest",
    "text": "Managing conflicts of interest\nConflicts of interest do not imply wrong-doing. It is the responsibility of the investigator to determine if any conflicts apply to any person/s involved in the design and/or conduct of the research study or any member of their immediate family. Disclose all contracts and any conflicts of interest (real, perceived, or potential) relating to this research project. Conflict of interest may also arise with regard to the disclosure of personal health information.\n\nNot applicable. There are no conflicts of interest to disclose.\nYes, there are conflicts of interest to disclose.\n\nIf yes, please describe the conflicts of interest (real, potential, and perceived), and the procedures for managing declared conflicts. Not applicable.",
    "crumbs": [
      "Ethics Protocol"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CITF-Postdoc",
    "section": "",
    "text": "This website serves as a hub for my postdoctoral research at McGill University’s Covid-19 Immunity Task Force Databank.\nThe project is concerned with articulating social, collaborative and discursive aspects of epidemiological data-sharing initiatives, and how they relate to, overlap with or conflict with technical, institutional and epistemic factors.\nThis website hosts a series of preparatory protocols that structure the project, as well as notes about key concepts and reflections on the progress of work. All content is hosted and tracked at github.com/zackbatist/CITF-Postdoc.\nResearch Protocol: Outlines the project’s overall vision and contextualizes it in relation to specific objectives.\nEthics Protocol: Specifies ethical considerations, including risks of harm and strategies for mitigating them.\nInterview Protocol: The questions I will be asking research participants, including the rationale for asking them.\nQDA Protocol: The code system, memoing guidelines, and specific QDA procedures.\nData Management: Procedures that circumscribe collection, management and curation of research data.\nCases: Articulates the parameters that inform how cases are selected.\nContext: My motivations for doing this work and the circumstances that surround the establishment of the project.\nGlossary: A series of key terms and their definitions, with reference to the literature and expanded notes about their meanings.\nBlog: Updates and reflections on key events, or general thoughts I wish to share.\nBib: A biblatex file containing a continually-updated list of sources cited in all documents hosted on this website.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\nJan 13, 2025\n\n\nMethodology notes\n\n\nreading, general thoughts\n\n\n\n\nJan 7, 2025\n\n\nMaelstrom reading notes\n\n\nreading\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Notes"
    ]
  },
  {
    "objectID": "notes/methodology-notes.html",
    "href": "notes/methodology-notes.html",
    "title": "Methodology notes",
    "section": "",
    "text": "x"
  },
  {
    "objectID": "notes/methodology-notes.html#case-studies",
    "href": "notes/methodology-notes.html#case-studies",
    "title": "Methodology notes",
    "section": "",
    "text": "x"
  },
  {
    "objectID": "notes/methodology-notes.html#grounded-theory",
    "href": "notes/methodology-notes.html#grounded-theory",
    "title": "Methodology notes",
    "section": "Grounded theory",
    "text": "Grounded theory\nx"
  },
  {
    "objectID": "posts/2024-12-09-first-team-meeting/index.html",
    "href": "posts/2024-12-09-first-team-meeting/index.html",
    "title": "Reflection on first team meeting",
    "section": "",
    "text": "Last week (2024/12/04) I finally met with David Buckeridge, Tanya Murphy and Aklil Noza in person. The meeting was meant to convey my vision for the project to the whole team, to align perspectives, and to articulate how this will actually work in practice.\nThe gist is that I will be investigating the role of social and cultural factors in data-sharing initiatives such as CITF and other Maelstrom-affiliated projects, and how these relate to, overlap with, or conflict with technical and institutional/administrative factors. To be clear, these are all very important aspects of data-sharing, but we generally recognized that the social and cultural aspects are under-explored relative to their impact.\nWe briefly talked about how we will go about selecting cases, and I emphasized the importance of strategic case selection. This also involves carefully articulating the project’s goals so that the cases will complement them. We agreed that the dataset will likely comprise between 12-15 interviews of around 60-90 minutes in length with representatives from 4-5 cases (one of them being CITF), in addition to representatives of the Maelstrom team. Maelstrom will serve as a “fixed point” that limits the scope of the cases’ breadth and ensures that participants have a common frame of reference. It also potentially allows me to “offload” or “consolidate” reference to technical and administrative aspects of data-sharing through targeted interviews with Maelstrom personnel, instead of dealing with those things with the representatives for each case.\nWe discussed timelines and overlap with Aklil’s work, which will be more concerned with focus groups with CITF databank users. There is definitely overlap with the emphasis of my own work and we will coordinate data collection to enhance the potential for analytical alignment.\nAfter the meeting I chatted with Tanya and Aklil who helped familiarize me with the bigger-picture theoretical discourse and tensions in epidemiology. Much of it seemed familiar since these concerns are common across disciplines, but I still need to read more to concretize my understanding. Tanya recommended I read the “Baby Rothman” which is a condensed version of a very long-lived textbook in this field, among a few other papers she sent me.\nOverall, this meeting got me really excited about this project :)"
  },
  {
    "objectID": "posts/2024-12-11-technical-specs/index.html",
    "href": "posts/2024-12-11-technical-specs/index.html",
    "title": "Technical specs for this website",
    "section": "",
    "text": "I’m using this website as a way to help organize and share key documents and resources. The research protocols are in flux at this stage in the project’s development, and this will make it easier to distribute up-to-date drafts with partners, while simultaneously enhancing transparency.\nThis post outlines the technical specifications for this website and outlines a roadmap for its further development. It will therefore be continually updated as the site evolves."
  },
  {
    "objectID": "posts/2024-12-11-technical-specs/index.html#fundamentals",
    "href": "posts/2024-12-11-technical-specs/index.html#fundamentals",
    "title": "Technical specs for this website",
    "section": "Fundamentals",
    "text": "Fundamentals\nThis website is based on Quarto, a platform for writing and publishing scientific and technical writing. I had used quarto before but without fully understanding it, and now I am starting to see its elegance.\nI had started off using Hugo, but there were too many limitations that Quarto was able to accomodate. You can find an older version of this post reflecting that setup here: #2346852.\nThe site is hosted on GitHub Pages. The repo is located at https://github.com/zackbatist/CITF-Postdoc."
  },
  {
    "objectID": "posts/2024-12-11-technical-specs/index.html#generating-pdfs",
    "href": "posts/2024-12-11-technical-specs/index.html#generating-pdfs",
    "title": "Technical specs for this website",
    "section": "Generating PDFs",
    "text": "Generating PDFs\nAs an avid user, one thing I really like about Quarto is the ability to generate PDFs alongside html versions served over the web. I started tinkering with includes but I need to review how Quarto passes info from YAML frontmatter. It is not at all straightforward and I will need to experiment a bit more with this to get the hang of it."
  },
  {
    "objectID": "posts/2024-12-11-technical-specs/index.html#archiving-and-version-control",
    "href": "posts/2024-12-11-technical-specs/index.html#archiving-and-version-control",
    "title": "Technical specs for this website",
    "section": "Archiving and Version Control",
    "text": "Archiving and Version Control\nEvery change is tracked using git. I would also like to archive each research protocol in Zenodo once they reach a point of stability. This would ensure that they ca be aassigned DOIs and detailed metadata, which will make them easier to reference.\nHowever, I do not want to rely on Zenodo’s GitHub integration for two reasons: (1) I want this to be as platform-agnostic as possible, and (2) that system relies on GitHub’s release system which operates on the level of the whole repository rather than specific files.\nI might be able to write a custom CI workflow to archive specific files to Zenodo using their API. But, I want to be able to toggle this option, rather than have it occur for every single detected change. Maybe I can accomplish this by pushing the changes that I want to archive to a dedicated branch that the CI workflow is configured to operate on. Or it might be easier to simply do this manually, since I’m not sure I will be using it that often anyway."
  },
  {
    "objectID": "research-protocol.html",
    "href": "research-protocol.html",
    "title": "Research Protocol",
    "section": "",
    "text": "Note\n\n\n\nThis document is still a work in progress.",
    "crumbs": [
      "Research Protocol"
    ]
  },
  {
    "objectID": "research-protocol.html#overview",
    "href": "research-protocol.html#overview",
    "title": "Research Protocol",
    "section": "Overview",
    "text": "Overview\nThis study investigates the social, technical, administrative and epistemic factors that mediate data-sharing initiatives in epidemiological research. It takes to heart the notions that data are media that facilitate communication across different research contexts, that data are created with specific intent, and that data are bounded by the social, practical and material circumstances of their creation. In light of these facts, I approach data-sharing as means of reconciling the varied circumstances of datasets’ creation — both among themselves, and in relation to contexts of reuse. I therefore frame data-sharing as efforts to foster a series of collaborative ties beyond a project’s original indended scope.\nData harmonization is one means of drawing the observations that constitute data into a formal schema, whose structure is driven by specific objectives and more general underlying suppositions and values. Although schemas are arrived at through discussion, compromise and consensus-building, with an eye toward practical outcomes afforded by the data model, these socially-mediated interactions are generally under-recognized as important factors contributing to data-sharing initiatives’ success relative to their potential impact.\nMy goal is to survey what factors are being priorized within various data harmonization initiatives, the rationales behind these decisions, and the relative efficacy of these variable approaches. More specifically, the project seeks to adress the following research questions:\n\nWhat are the objectives of data-sharing initiatives, how were they established, and what progress has been made to achieve them?\nWhat strategies do data-sharing initiatives employ to ensure they are able to meet their objectives, and how effective are they?\nWhat values underlie these strategies, and can they be linked with effective outcomes?\n\nTo be clear, my intent is not to pit various approaches against each other, but rather to ascertain what actions specific strategies entail, the circumstances in which each is adopted, the value that they bring, and the trade-offs involved. In other words, my goal is to reveal the diverse ways in which data-sharing occurs, and how different approaches impact the outcomes in different ways.",
    "crumbs": [
      "Research Protocol"
    ]
  },
  {
    "objectID": "research-protocol.html#background",
    "href": "research-protocol.html#background",
    "title": "Research Protocol",
    "section": "Background",
    "text": "Background\nStill in progress…\n- About open data infrastructures in general\n  - Discrepancies between aspirations and effective outcomes\n  - Based on models of science that diverge from practical experience\n- About open data in epidemiology\n  - What is driving it?\n  - Introduce Maelstrom as a key player\n- Challenges and opportunities in the Canadian context",
    "crumbs": [
      "Research Protocol"
    ]
  },
  {
    "objectID": "research-protocol.html#methodology",
    "href": "research-protocol.html#methodology",
    "title": "Research Protocol",
    "section": "Methodology",
    "text": "Methodology\n\nApproach\nThis study is informed by a set of theoretical and methodological frameworks formed within a more interdisciplinary “science studies” tradition, which contribute to a more sociological outlook on science as cultural practice (cf. Pickering 1992). In practical terms, I will document the social and collaborative experiences involved in various research practices, which ultimately bind the many ways in which scientists do science.\nI will specifically focus on how people contribute to and extract from information commons, which comprise both formal documents and mutually-held and information-laden situated experiences. This involves examining the ways in which participation in disciplinary or even more specialized communities of practice fosters mutual understanding about the potential and limitations pertaining to other people’s data; and how this communally-held knowledge is accessed and re-produced. This approach aligns with the situated cognition methodological framework for examining the improvised, contingent and embodied experiences of human activity, including science (cf. Suchman 2007; Knorr Cetina 2001).\nThe situated cognition framework prioritizes subjects’ outlooks, which are contextualized by their prior experiences, and enables scholars to trace how people make sense of their environments and work with the physical and conceptual tools available to them to resolve immediate challenges. Situated cognition therefore lends itself to investigating rather fluid, open-ended and affect-oriented actions, and is geared towards understanding how actors draw from their prior experiences to navigate unique situations.1\n1 I expand on this in my extended note on efforts to frame the plurality of research experiences as a continuum of practice.Situated cognition is especially salient in explorations of how people who are learning new skills learn how to work in new and possibly unfamiliar ways, and in this sense is closely related to Lave and Wenger’s (1991) theory of situated learning (or ‘communities of practice’ approach), which focuses on how individuals acquire professional skills in relation to their social environments. In such situations, situated cognition enables observers to examine how people align their perspectives as work progresses, and to understand better how people’s general outlooks may have changed under the guidance of more experienced mentors. In other words, situated cognition enables researchers of scientific practices to account for discursive aspects of work, including perceived relationships, distinctions or intersections between practices that professional or research communities deem acceptable and unacceptable, and the cultural or community-driven aspects of decisions that underlie particular actions.\nIn taking on this theoretical framework, I frame epidemiology as a collective endeavour to derive a coherent understanding of population-level health trends, which involves the use of already established knowledge in the validation of newly formed ideas, and which relies on systems designed to carry information obtained with different chains of inference. These systems have both technical and social elements. The technical elements are the means through which information becomes encoded onto information objects so that they may form the basis for further inference. The social elements constitute a series of norms or expectations that facilitate the delegation of roles and responsibilities among agents who contribute their time, effort and accumulated knowledge to communal goals.\nAs such, in constructing the arguments of this study and in carrying out the fieldwork that grounds it, I will rely upon both realist and constructivist viewpoints. In one sense, I rely on documenting how people actually act, including the longer-term and collaborative implications that their actions may have on other work occurring throughout the continuum of practice. To accomplish this, I identify research activities from the perspective of an outside observer. I also ascribe meanings to things (such as physical or conceptual tools, or objects that captivate subjects’ interests) in ways that conform to my own perspective as an investigator of scientific research practices. On the other hand, a constructionist perspective enables me to consider how individual agents make components of information systems suit their needs to facilitate communication or interoperability among actors who hold different situated perspectives. By listening to participants’ views about the systems with which they engage, including explanations as to why they act in the ways that they do, I am able to trace the assumptions and taken-for-granted behaviours that frame their perspectives. Moreover, these insights are useful for developing a better understanding of how participants identify with particular disciplinary communities and their perception of their roles within broader collective efforts.\nUltimately, this study is about the social order of scientific research, i.e. the frameworks, mindsets or sets of values that humans adopt to carry out their work in specific ways. Human beings rely upon physical and conceptual apparatus to do this work but, in order to understand how they do science in ways that conform to the epistemic mandates of the scientific enterprise, it is necessary to prioritize attention to human intention, drivers and pressures. I am emphasizing the agency of human drivers — as opposed to tools and procedures2 — since humans are the ones who (a) identify problems that need to be resolved; (b) imagine, project or predict potential outcomes of various kinds of actions that they may select to resolve the challenges; and (c) learn from prior experiences and change their behaviours accordingly. By highlighting how pragmatic actions are conducted in relation to broader social and discursive trends and tendencies, I consider scholarly practices in terms of potential, certainty and desire from the perspectives of practitioners themselves.\n2 Human and non-human agents are considered on equal footing under the Actor-Network Theory (ANT) framework, which has become very popular since its origins in the late 1980s, but which may not be suitable for this approach. See my extended note on this for further details.\n\nData\nThis project will draw from around 12-15 interviews with epidemiological researchers who lead and carry out initiatives to share and harmonize data. Interviewees will comprise members of several projects that partner with the Maelstrom research group, a service that supports data harmonization efforts in the field of epidemiology. See the case selection strategy document for further information on how cases are decided upon.\nInterviews will be oriented by my goal to document processes of reconciling different stakeholders’ interests as they converge in the formation of a common data stream. Specifically, interviews will focus on motivations for their initiatives, the challenges they experience, how they envision success and failure, their perceptions of their own roles and the roles of other team members and stakeholders, the values that inform their decisions, how the technological apparatus they set up enables them to realize their goals and values, and ways in which they believe data-sharing could be improved. See the interview protocol for further details on the questions I will ask and how their responses will contribute to the project’s findings, as well as logistical considerations.\nI will transcribing the interviews and edit the transcripts so that they conform with transcript notation standards (e.g. GAT-2, see Selting, Auer, and Barth-Weingarten 2011) and so they are optimally formatted for application in qualitative data analysis software. I will use automated speech recognition and natural language processing to create preliminary transcripts, which I will then manual edit.\nI will collect and handle all data in full compliance with the ethics protocol. I will present an overview of the research objectives to all participants and obtain verbal consent prior to each interview before proceeding. Interviewees will be given the option to obfuscate any identifying information in processed records, and I will reiterate this option immediately after the interview and in a follow-up email one week following the interview.\nData will be curated according the data management plan.\n\n\nMethods\nI will perform qualitative data analysis (QDA) methods to highlight collaborative aspects of data harmonization work, as elicited in the interviews. QDA involves encoding the primary sources of evidence in ways that enable a researcher to draw cohesive theoretical accounts or explanations. This is done by tagging segments of a document (such as an interview transcript) using codes, and by embedding open-ended interpretive memos directlly alongside the data. Through these methods, I am able to articulate theories based on empirical evidence that reflect my informants’ diverse experiences.\nCoding — which involves defining what specific elicitations are about in terms that are relevant to the theoretical frameworks that inform my research — entails rendering instances within a text as interpreted abstractions called codes (Charmaz 2014, 43). Codes can exist at various levels of abstraction. For instance, I may apply descriptive codes to characterize literal facets of an instance within a text, and theoretical codes to represent more interpretive concepts that correspond with aspects of particular theoretical frameworks. I tend to create codes on the fly as “open codes” when prompted by encounters with demonstrative instances in the text. However, as I create new codes, I situate them within a hierarchical code system that provides me with a rough taxonomic structure to help organize my work and to enable me to more effectively query the data. Coding in this manner involves synthesis of concepts that speak to my understanding of the phenomena of interest, while forcing me to remain receptive to limits imposed by what is actually contained in the text. In other words, coding involves applying a precise language to segments of transcribed interviews that serve to bridge the gap between what participants said and the theoretical frameworks I apply to explore them as epistemic activities, interfaces and values (cf. Charmaz 2014; Saldaña 2011, 95–98).\nMemoing entails more open-ended exploration and reflection upon latent ideas in order to crystallize them into new avenues to pursue (Charmaz 2014, 72). Constructing memos is a relatively flexible way of engaging with data and serves as fertile ground for honing new ideas. Memoing is especially crucial while articulating sensitizing concepts, which Charmaz (2003, 259) refers to as the “points of departure from which to study the data”. Memoing allows me to take initial notions that lack specification of well-defined attributes, and gradually refine them into more cohesive, definitive concepts (Blumer 1954, 7; Bowen 2006). Exploring the main features, relationships or arrangements that underlie a superficial view of a sensitizing concept through memoing helps me to identify what kinds of things I need to locate in the data in order to gain a full understanding of the phenomena of interest. Memoing is also very important in the process of drawing out more coherent meaning from coded data (cf. Charmaz 2014, 181, 290–93). By creating memos pertaining to the intersections of various codes and drawing comparisons across similarly coded instances, I am able to form more robust and generalizable arguments about the phenomena of interest and relate them to alternative perspectives expressed by others.\nThroughout my analysis, I will follow the approach that Nicolini (2009) and Maryl et al. (2020, para. 30) advocate, who suggest “zooming in to a granular study of particular research activities and operations and zooming out to considering broader sociotechnical and cultural factors.” This involves “magnifying or blowing up the details of practice, switching theoretical lenses, and selective re-positioning so that certain aspects are fore-grounded and others are temporarily sent to the background” (Nicolini 2009, 1412). This approach is useful for me because research projects all start from different positions but share common practices and tendencies that vary according to those contextual circumstances. I am therefore able to tactfully switch between those lenses to understand the interplay between circumstances and practical implementations, which vary across cases, which have their own histories, memberships, sets of tools, methods, and social or political circumstances.ships, sets of tools, methods, and social or political circumstances.\nI will perform all of this work using MaxQDA, a QDA software suite that stores all of these connections within a centralized database (VERBI Software 2021).3 This allows me to retrieve segments of text from across various documents that have been assigned the same sets of codes, and perform more complex queries that search along different parameters of overlap, intersection, and exclusion. I will then be able to query the integrated dataset to produce elaborated accounts of specific kinds of activities, decisions, values and sentiments.\n3 I am most familiar with MaxQDA from my doctoral research. NVivo is another popular proprietary software suite with overlapping functionality, and QualCoder, OpenQDA and QCoder are open source implementations. In my experience, MaxQDA is the most feature-rich option and has a well-crafted interface that suits my needs well.See the QDA protocol for further details on the code system and memoing guidelines, as well as specific QDA procedures.",
    "crumbs": [
      "Research Protocol"
    ]
  },
  {
    "objectID": "research-protocol.html#expected-outcomes-and-impact",
    "href": "research-protocol.html#expected-outcomes-and-impact",
    "title": "Research Protocol",
    "section": "Expected Outcomes and Impact",
    "text": "Expected Outcomes and Impact\n\nScholarly outputs\nThis project will produce three articles. One of these will be published in a journal concerned with scientific practice or research data management (e.g. Computer Supported Cooperative Work). Another will be published in a journal dedicated to advancing research practices in epidemiology (e.g. Epidemiologic Methods) Finally, I will publish a more practically-oriented set of guidelines deriving from the findings, as either an editorial or as a “10 simple rules” style article.\nI will also present this work at conferences and workshops, but specifics have yet to be determined.\n\n\nPractical outcomes\nWhile this research is critical, it is intended to be constructive. It is therefore necessary to ensure that the findings may be put to practical use so as to enhance and improve data-sharing initiatives. While a “10 simple rules” article will be a handy brief of my findings, I would also like to contribute to the development of data-sharing infrastructures and policies in a more active manner. Specifically, I will reach out to leading stakeholders directly by highlighting our common interest in developing more effective data-sharing infrastructures and presenting a series of practical ideas for improving their services. I will ensure that these meetings conclude with a series of action items which will enable us to foster an outcome-oriented and productive relationship directed toward achieving tangible goals.\nStill in progress…\n- Support efforts to enhance data reuse potential of the CITF Databank specifically\n- Submit comments to CIHR with regards to their ongoing revisions to federal open science policies\n\n\nBroader outreach\nStill in progress…\n- Submit something to [The Conversation](https://theconversation.com/ca)\n- Collaboration with the [School of Information Studies](https://www.mcgill.ca/sis/)",
    "crumbs": [
      "Research Protocol"
    ]
  },
  {
    "objectID": "research-protocol.html#timelime",
    "href": "research-protocol.html#timelime",
    "title": "Research Protocol",
    "section": "Timelime",
    "text": "Timelime\n\n\n\n\n\n\n\nDate\nMilestone\n\n\n\n\n2025/01/14\nFinalize ethics protocol\n\n\n2025/01/31\nFinalize case selection and invite members to participate\n\n\n2025/01/21\nFinalize data managemenrt plan\n\n\n2025/02/14\nFinalize interview protocol\n\n\n2025/02/14 — 2025/03/31\nConduct interviews\n\n\n2025/04/01 — 2025/04/30\nPrepare interview transcripts for analysis\n\n\n2025/05/01 — 2025/05/31\nPrepare code system and develop sensitizing concepts\n\n\n2025/06/01 — 2025/09/30\nQualitative coding and memoing\n\n\n2025/10/01 — 2025/11/30\nDraft manuscripts and submit for publication\n\n\n2025/11/01 — 2025/12/31\nWrite accessible and constructive reports",
    "crumbs": [
      "Research Protocol"
    ]
  }
]