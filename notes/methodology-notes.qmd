---
title: Methodology notes
description: Notes perpainting to the methodological approach for this project.
date: 2025-01-13
date-modified: last-modified
toc-depth: 5
categories: 
  - reading
  - general thoughts
---

This document is an overview of methodological topics and concerns.
It is a place where I think through and justify my methodological decisions, and identify the methods and procedures through which I implement them.

<!--
## Some nomenclature
Before proceeding, it's necessary to clarify a few key terms and concepts:

**Methodology:**


**Method:**
The series of tools, techniques and procedures that structure coordinated action.

**Task:**
Goals that are constrained by specific conditions, which need to be achieved in concert or in tandem to achieve an overarching objective.
In order to realize these goals, actors conduct **actions**, which are dictated by these practical conditions.

**Procedure:**
The formal, official or pre-defined series of actions that inform how actors should complete a task.
Documented through **protocols**.


Here's a little glossary summarizing some key terms and concepts:

- methodology
  - the principles of methods, rules, and postulates employed by a discipline
  - uncovering assumptions and practices associated with the different methods and a detailed description of research designs and hypothesis testing
  - Methodology can be understood as the middle ground between concrete particular methods and the abstract and general issues discussed by the philosophy of science
  - In this regard, methodology comes after formulating a research question and helps the researchers decide what methods to use in the process. For example, methodology should assist the researcher in deciding why one method of sampling is preferable to another in a particular case or which form of data analysis is likely to bring the best results. Methodology achieves this by explaining, evaluating and justifying methods.
  - According to Aleksandr Georgievich Spirkin, "[a] methodology is a system of principles and general ways of organising and structuring theoretical and practical activity, and also the theory of this system".[16][17] Helen Kara defines methodology as "a contextual framework for research, a coherent and logical scheme based on views, beliefs, and values, that guides the choices researchers make".[18] Ginny E. Garcia and Dudley L. Poston understand methodology either as a complex body of rules and postulates guiding research or as the analysis of such rules and procedures. As a body of rules and postulates, a methodology defines the subject of analysis as well as the conceptual tools used by the analysis and the limits of the analysis.
  - John Law: Against Method
- method
  - A method is a way of reaching some predefined goal.
  - It is a planned and structured procedure for solving a theoretical or practical problem.
  - They give structure to action.
- procedure
  - May be interchangeable with "technique"
- protocol
- 
-->

## Significant Concepts and Frameworks
### Multicase Studies
These notes describe the features, affordances and limitations of case study research, and articules factors correspoding with variable kinds of case studies.

I do notice a distinction between two schools of thought, which seem to be spearheaded by Stake and Yin.
I generally favour Stake's flexible approach, and it seems well aligned with other methodological works I've been reading [e.g. @abbott2004; @ragin1992a].

#### Stake's Approach
In case-study research, cases represent discrete instances of a phenomenon that inform the researcher about it.
The cases are not the subjects of inquiry, and instead represent unique sets of circumstances that frame or contextualize the phenomenon of interest [@stake2006: 4-7].

Cases usually share common reference to the overall research themes, but exhibit variations that enable a researcher to capture different outlooks or perspectives on matters of common concern.
Drawing from multiple cases thus enables comprehensive coverage of a broad topic that no single case may cover on its own [@stake2006: 23].
In other words, cases are contexts that ascribe particular local flavours to the activities I trace, and which I must consider to account fully for the range of motivations, circumstances and affordances that back decisions to perform activities and to implement them in specific ways.

Moreover, the power of case study research derives from identifying consistencies that relate cases to each other, while simultaneously highlighting how their unique and distinguishing facets contribute to their representativeness of the underlying phenomon.
Case study research therefore plays on the tensions that challenge relationships among cases and the phenomenon that they are being called upon to represent [@ragin1999: 1139-1140].

Stake [-@stake2006: 4-6] uses the term **quintain**^[The term refers to a medieval jousting target: see <https://en.wikipedia.org/wiki/Quintain_(jousting)>] to describe the group, category or phenomenon that bind together a collection of cases.
A quintain is an object, phenomenon or condition to be studied -- "a target, not a bull's eye" [@stake2006: 6].
"The quintain is the arena or holding company or umbrella for the cases we will study" [@stake2006: 6].
The quintain is the starting point for multi-case research.

According to Stake [-@stake2006: 6]:

> Multicase research starts with the quintain.
> To understand it better, we study some of its single cases --- its sites or manifestations.
> But it is the quintain we seek to understand.
> We study what is similar and different about the cases in order to understand the quintain better.

Stake [-@stake2006: 8] then goes on:

> When the purpose of a case is to go beyond the case, we call it an "instrumental" case study 
> When the main and enduring interest is in the case itself, we call it "intrinsic" case study [@stake1988].
> With multicase study and its strong interest in the quintain, the interest in the cases will be primarily instrumental.

Abbott's [-@abbott2004: 22] characaterization of Small-N  comparison is very reminiscient of Stake's -@stake2006 account of the case-quintain dialectic:

> Small-N comparison attempts to combine the advantages of single-case analysis with those of multicase analysis, at the same time trying to avoid the disadantages of each.
> On the one hand, it retains much information about each case.
> On the other, it compares the different cases to test arguments in ways that are impossible with a single case.
> By making these detailed comparisons, it tries to avoid the standard critcism of single-case analysis --- that one can't generalize from a single case --- as well as the standard criticism of multicase analysis --- that it oversimplifies and changes the meaning of variables by removing them from their context.

It should be noted that case study research limits my ability to define causal relationships or to derive findings that may be generalized across the whole field of epidemiology.
This being said, case study research allows me to articulate the series of inter-woven factors that impact how epidedemiological researchers coordinate and participate in data-sharing initiatives, while explicitly accounting for and drawing from the unique and situational contexts that frame each case.

Stake [-@stake2006: 23] recommends selecting between 4-10 cases and identifies three main criteria for selecting cases:

- Is the case relevant to the quintain?
- Do the cases provide diversity across contexts?
- Do the cases provide good opportunities to learn about complexity and contexts?

> For qualitative fieldwork, we will usually draw a purposive sample of cases, a sample tailored to our study; this will build in variety and create opportunities for intensive study [@stake2006: 24].^[Though Yin [-@yin2014: 40-444] is dismissive of such use of the term "sample" since he sees case study research as only generalizable to similar situations, and not to a general population from which a sample is typically said to be drawn. I agree with this focus on concrete situations over Stake's prioritization of theory-building as an end unto itself.]


Stake's [-@stake2010: 122] prioritizes doing research to understand something or to improve something, and I generally agree with his rationalization; research helps reframe problems and establish different decision options.

#### Yin's Approach
According to Yin [-@yin2014: 16], "a case study is an empirical inquiry that investigates a contemporary phenomenon (the "case") in depth and within its real-world context, especially when the boundaries between phenomenon and context may not be clearly evident."

He goes on to document some features of a case study: "A case study inquiry copes with the technically distinctive situation in which there will be many more variables of interest than data points, and as one result relies on multiple sources of evidence, with data needing to converge in a triangulating fashion, and as another result benefits from the prior development of theoretical propositions to guide data collection and analysis." [@yin2014: 17]

@yin2014 is more oriented toward what he refers to as a _realist_ perspective, which he pits against _relativist_ and _interpretivist_ perspectives (used interchangably, it seems), and which I might refer to as _constructivist_.
He characterizes relativist perspectives as "acknowledging multiple realities having multiple meanings, with findings that are observer dependent".
His prioriting of a realist approach corresponds with the analysis by @yazan2015, who compared Yin with Stake and Merriam.
According to  Yazan [-@yazan2015: 137], Yin evades making statements about his epistemic commitments, and is characterized as post-positivist.

@yin2014 is very concerned with _research design_ in case study research
He posits that, in a colloquial sense, "a research design is a logical plan for getting from here to there, where here may be defined as the initial set of questions to be answered, and there is some set of conclusions (answers) about these questions." [@yin2014: 28]

Yin distinguishes between a research design and a work plan.
A research design deals with a logical problem, whereas a work plan deals with a logistical problem.
Seems reminiscient of Brian Cantwell Smith's distinction between skeletons and outlines.

Yin lists five components of a research design:

1. A case study's questions;
2. its propositions, if any;
3. its unit(s) of analysis;
4. the logic linking the data to the propositions; and
5. the criteria for interpreting the findings.

Interestingly, I have been instinctively following these steps, and am currently hovering somewhere between components 3 and 4, while dipping back to 2 once in a while too.

The problem of defining the unit of analysis is salient to me right now.
According to Yin [-@yin2014: 32], the unit of analysis may change as the project progresses, depending on initial misconceptions (he uses the example of a unit of analysis changing from neighbourhoods to small groups, as contextualized by the socio-geographical entity of the neighbourhood, which is laden with issues of class, race, etc).
In my own situation, the unit of analysis may hover between the harmonization initiative, the people, activities or infrastructures that make it work.

In the section on criteria for interpreting the findings, Yin emphasizes the role of rival theories, which is akin to a concern with falsifiability as a means of validating truth claims, and which betrays his positivist leanings.
This may be compared with Stake's emphasis on triangulation, which is more concerned with internal cohesiveness.
Similarly, Yin cites Corbin and Strauss regarding the role of theory or theoretical propositions in research design, which similarly reveals a concern with rigorous upfront planning and strict adherence to research design as a key aspect of deriving valid findings.

Regarding generalizability, Yin [-@yin2014: 40-41] states that "Rather than thinking about your case as a sample, you should think of it as the opportunity to shed empirical light about some theoretical concepts or principles, not unlike the motive of a laboratory investigator in conceiving of and then conducting a new experiment."
He goes on to state that case studies tend to strive for analytic generalizations that go beyond the specific case that has been studied, and which apply to other concrete situations rather than just abstract theory building.

#### Logistics of case study design
##### Preparing to select case study data
Yin [-@yin2014: 72-23] identifies five desired attributes for collecting case studt data:

1. Ask good questions --- and interpret answers fairly.
  - "As you collect case study evidence, you must quickly review the evidence and continually ask yourself why events or perceptions appear as they do." (73)
  - A good indicator of having asked good questions is mental and emotional exhaustion at the end of each fieldwork day, due to the depletion of "analytic energy" associated with being attention on your toes. (73-74)
2. Be a good "listener" not trapped by existing ideologies or preconceptions.
  - Sensing through multiple modalities, not just spoken words.
  - Also subtext, as elicited through choices of terms used, mood and affective components. (74)
3. Stay adaptive, so that newly encountered situations can be seen as opportunities, not threats.
  - Remember the original purpose but willing to adapt to unanticipated circumnstances. (74)
  - Emphasize balancing adaptability with rigour, but not with rigidity. (75)
4. Have a firm grasp of what is being studied, even when in an exploratory mode.
  - Need to do more than merely record data, but interpret information as they are being collected and to know immedately whether there are contradictions or complementary statements to follow-up on. (75-76)
5. Avoid biases of being sensitive to contrary evidence, also knowing how to conduct research ethically.
  - Maintain strong professional competence, including keeping up with related research, ensuring accuracy, striving for credibility, and knowledging and mitigating against bias.

Yin advocates for adoption of case study protocols.
He provides an example of a table of contents for case study protocols, which generally comprise four sections:

1. Overview of the case study
2. Data collection procedures
3. Data collection questions
4. Guide for the case study report

##### Triangulation
Triangulation is a process of gaining assurance.
Also sometimes called crystallization.

"Each important finding needs to have at least three (often more) confirmations and assurances that key meanings are not being overlooked." [@stake2006: 33]
Triangulation is a process of repetitous data gathering and critical review of what is being said. [@stake2006: 34]

What needs triangulation? [@stake2006: 35-36]

- If the description is trivial or beyond question, there is no need to triangulate.
- If the description is relevant and debatable, there is much need to triangulate.
- If the data are critical to a main assertion, there is much need to triangulate.
- If the data are evidence for a controversial finding, there is much need to triangulate.
- If a statement is clearly a speaker's interpretation, there is little need to triangulate the quotation but not its content.

Stake [-@stake2006: 37] cites @denzin1989 who highlighted several kinds of triangulation, leading to a few advisories:

- Find ways to use multiple rather than single observers of the same thing.
- Use second and third perspectives, i.e. the views of teachers, student and parents.
- Use more than one research method on the same thing, i.e. document review and interview.
- Check carefully to decide how much the total description warrants generalization.
  - Do your conclusions generalize across other times or places?
  - Do your conclusions about the aggregate generalize to individuals?
  - Do findings of the interaction among individuals in one group pertain to other groups?
  - Do findings of the aggregate of these people generalized to a population?

##### Cross-Case Analysis Procedure
Stake [-@stake2006: Chapter 3] lays out a procedure for deriving synthetic findings from data collected across cases.
He frames this in terms of a dialectic between cases and quintains.
He identifies three tracks [@stake2006: 46]:

- Track 1: Maintains the case findings and the situationality.
- Track 2: Merges similar findings, maintaining a little of the situationality.
- Track 3: The most quanitative track, shifts the focus from findings to factors.

According to Stake, case reports should be created independently and then brought together by a single individual when working in a collaborative project.
In keeping with the case-quintain dialectic, this integration must involve strategically putting the cases aside and bringing them back in to identify convergences and divergences, similarities and differences, normalitities and discrepancies among them.

There is some detailed discussion about different kinds of statements, i.e. themes, findings, factors and assertions, but I find this a bit too much detail for me to get at at this point in mymethodological planning.
In general though, Stake documents a process whereby an analyst navigates back and forth between the general and the situational, presenting tentativr statements that are shored up, modified or discarded through testing compatability of the evidence across cases.

##### Single cases
@stake2000 is concerned with identifying what can be learned from a single case.
He [-@stake2000: 437] identifies three kinds of cases:

- **Intrinsic case studies** as being driven by a desire to understand the particular case.
- **Instrumental case studies** are examined "mainly to provide insight into an issue or to redraw a generalization."
- **Collective case studies** "investigate a phenomenon, population or general condition".

@stake2000 frames case research around a tension between the particular and the general, which echoes the case-quintain dilemma he described in [@stake2006: 4-6].

##### Some scattered practical guidance
Stake [-@stake2006: 18-22] provides a detailed and realistic overview of common challenges involved in collaborative qualitative research.
This could be handy in future work when planning a multicase project involving multiple researchers.

Stake [-@stake2006: 29-33] provides guidance on how to plan and conduct interviews in multicase research, including a series of helpful prompts and questions to ask yourself while designing the interview.
One thing that stands out is his recommendation that an interview should be more about the interviewee than about the case.
It's necessary to find out about the interviewee to understand their interpretations, but what they reveal about the quintain is more important.

On page 34, @stake2006 also provides some practical tips for documenting and storing data, after @huberman1994.

Stake [-@stake2006: Chapter 4] includes a chapter on procedures for reporting the findings, and I may return to this later on once I need to initiative this phase of work.
It addresses concerns about how to articulate comparisons, concerns about generalization, and how to handle advocacy based on findings.

See @stake2006 Chapter 5 for a step-by-step overview of a multicase study analysis.
The rest of the volume after that includes three very detailed examples from his own work.

### Grounded theory
These notes are largely drawn from @charmaz2000, which I understand to be a fairly balanced and comprehensive overview of the Glaser / Strauss and Corbin debate, and of the situation of specific methods and techniques in relation to these different stances.
I also value Charmaz's position as someone who subscribes to her constructivist approach.

According to Charmaz[-@charmaz2000: 509]:

> Essentially, grounded theory methods consist of systematic inductive guidelines for collecting and analyzing data to build middle-range theoretical frameworks that explain the collected data.

Charmaz[-@charmaz2000: 511] goes on to situate grounded theory in relation to what was the norm prior to its invention:

> Glaser and Strauss's (1967) work was revolutionary because it challenged (a) arbitrary divisions between theory and research, (b) views of qualitative research as primarily a precursor to more "rigorous" quantitative methods, (c) claims that the quest for rigor made qualitative research illegitimate, (d) beliefs that qualitative methods are impressionistic and unsystematic, (e) separation of data collection and analysis, and (f) assumptions that qualitative research could produce only descriptive case studies rather than theory development [@charmaz1995].

Prior to @glaser1967, qualitative analysis was taught rather informally --- they led the way in providing written guidelines for systematic qualitative data analysis with explicit procedures for data analysis [@charmaz2000: 512]

Glaser brought his very positivist assumptions from his work at Columbia, and Strauss' work in Chicago with Herbert Blumer and Robert Park infused a pragmatic philosophical approach to the study of process, action and meaning that reflects symbolic interactionism.

#### Glaser
Glaser's position comes close to traditional positivism, with assumptions of an objective, external reality and a neutral observer who discovers data. and a reductionist form of inquiry of manageable research problems.
According to Charmaz [-@charmaz2000: 511], regarding Glaser's approach:

> Theoretical categories must be developed from analysis of the collected data and must fit them; these categories must explain the data they subsume.
> This grounded theorists cannot shop their disciplinary stores for preconceived concepts and dress their data in them.
> Any existing concept must earn its way into the analysis.
> ...
> The relevance of a grounded theory derives from its offering analytic explanations of actual problems and basic processes in the research setting.
> A grounded theory is durable because researchers can modify their emerging or established analyses as conditions change or further data are collected.


#### Corbin and Strauss
Strauss and Corbin assume an objective reality, aim toward unbiased data collection, propose a series of technical procedures, and espouses verification.
However, they are postpositivism because they propose giving voice to their respondents,^[Charmaz uses the term "giving voice" in this specific context. I'm not sure if this is meant to represent Strauss and Corbin's attitude, and whether this is an accurate representation on their views, but in my mind this should be framed as elevating, amplifying or re-articulating respondents' voices (and this is a tenet of constructivist grounded theory in general, which derives from Charmaz). My take diverges from the position that we "give voice" to respondents in that it acknowledges (1) that the voices are already there, (2) that respondents are in fact _giving us_ their voices, and (3) that the researcher plays an active editorial role, transforming the respondents' elicitations into a format that is more amenable to analysis.] representing them as accurately as possible, discovering and reckoning with how their respodents' views on reality differ from their own, and reflecting on the research process as one way of knowing.

Corbin and Strauss (1990) "gained readers but lost the sense of emergence and open-ended character of Strauss's earlier volume and much of his empirical work. The improved and more accessible second edition of _Basics_ [@strauss1998] reads as less prescriptive and aims to lead readers to a new way of thinking about their research and about the world." [@charmaz2000: 512]

Strauss apparently became more insistent that grounded theory should be more verificational in nature in personal communications.

@glaser1992 responded to @strauss1990, repudiating what he perceived as forcing preconceived questions and frameworks on the data.
Glaser considered it better to allow theory to "emerge" from the data, i.e. to let the data speak for themselves.

Charmaz identifies these two approaches as having a lot in common: hey both advocate for mitigating factors that would hinder objectivity and minimize intrusion of the researcher's subjectivity, and they are both embedded in positivist attitudes, with a researcher sitting outside the observed reality; Glaser exemplifies these through discovering and coding data, and using systematic comparative methods, whereas Strauss and Corbin maintain a similar distance through their analytical questions, hypotheses and methodological applications.
They both engage in "silent authorship" and usually write about their data as distant experts [@charmaz1996].

#### Constuctivist Grounded Theory
> Constructivist grounded celebrates firsthand knowledge of empirical worlds, takes a middle ground between postmodernsm and positivism, and offers accessible methods for taking qualitative research into the 21st century. (510)

> The power of grounded theory lies in its tools for understanding empirical worlds.
> We can reclaim these tools from their positivist underpinnings to form a revised, more open-ended practice of grounded theory that stresses its emergent, constructivist elements.
> We can use grounded theory methods as flexible, heuristic strategies rather than as formulaic procedures. (510)

Three aspects to Charmaz's argument (510):^[Very much in line with the pragmatist turn of the late '90s and early '00s, as also documented by Lucas [-@lucas2019: 54-57] in the context of archaeological theory, vis-a-vis positivism, postmodernism, and settling on a middle ground between them.]

1. Grounded theory strategies need not be rigid or prescriptive;
2. a focus on meaning while using grounded theory _furthers,_ rather than limits, interpretive understanding; and
3. we can adopt grounded theory strategies without embracing the positivist leanings of earlier proponents of grounded theory.

Repudiation of the notion that data speak for themselves, that data do not lie.
Recognition that data are constructs of the rsearch process, are framed by the questions we ask informants and the methodological tools of our collection procedures.

Charmaz [-@charmaz2000: 515] advocates for what seems to be a dialogical approach to coding, between researcher and the data:

> We should interact with our data and pose questions to them while coding.
> Coding helps us to gain a new perspective on our material and to focus further data collection, and may lead us in unforeseen directions.
> Unline quantitative research that requires data to fit into _preconceived_ standardized codes, the researcher's interpretations of data shape his or her emergent codes in grounded theory.

Distinguishes articulates open/initial coding as proceeding line by line to get a general sense of what the data contains.
It is meant to keep the researcher close to the data, to remain attuned to the subjects' views of their realities.

> Line-by-line coding sharpens our use of sensitizing concepts --- that is, those background ideas that inform the overall research problem.
> Sensitizing concepts offer eays of seeing, organizing, and understanding experience; they are embedded in our disciplinary emphases and perspectival proclivities.
> Although sensitizing conceots may deepen perception, they provide starting points for building analysis, not ending points for evading it.
> We may use sensitizing concepts _only_ as points of departure from which to study the data.

Much of the rest of the @charmaz2000 paper is an overview of coding and memoing methods, as well as theoretical sampling.
The emphasis is on situating these techniques in the Glaser / Strauss and Corbin debate, and it will be better to refer to @charmaz2014 for in-depth notes on these techniques.

Charmaz [-@charmaz2000: 521-522] provides an apt account of a significant critique of grounded theory, and poses her constructivist approach as a potential means of resolving it.
Specifically, she refers to the notion that grounded theory (as traditionally conceived by both Glaser and Strauss and Corbin) "fractures" the data, making them easier to digest in an analytical sense, but also making it more difficult to engage with in a holistic manner.
This is precisely the point of the original approach, to present qualitative data as data --- as conceived and valued by quantitative researchers, i.e. as discrete, corpuscular, disembodied, re-arrangable and distant entities.
The text of these two large paragraphs is copied here:

> @conrad1990 and @riessman1990 suggest that "fracturing the data" in grounded theory research might limit understanding because grounded theorists aim for analysis rather than the portrayal of subjects' experience in its fullness.
> From a grounded theory perspective, fracturing the data means creating codes and categories as the researcher defines themes within the data.
> @glaser1967 propose this strategy for several reasons: (a) to help the researcher avoid remaining immersed in anecdotes and stories, and subsequently unconsciously adopting subjects' perspectives; (b) to prevent the researcher's becoming immobilized and overwhelmed by voluminous data; and (c) to create a way for the researcher to organize and interpret data.
> However, criticisms of fracturing the data imply that grounded theory methods lead to separating the experience from the experiencing subject, the meaning from the story, and the viewer from the viewed.
> In short, the criticisms assume that the grounded theory method (a) limits entry into subjects' worlds, and thus reduces understanding of their experience; (b) curtails representation of both the social world and subjective experience; (c) relies upon the viewer's authority as expert observer; and (d) posits a set of objectivist procedures on which the analysis rests.
>
> Researchers can use grounded theory methods to further their knowledge of subjective experience and to expand its representation while neither remaining external from it nor accepting objectivist assumptions and procedures.
> A constructivist grounded theory assumes that people create and maintain meaningful worlds through dialectical processes of conferring meaning on their realities and acting within them [@bury1986; @mishler1981].
> Thus social reality does not exist independent of human action.
> Certainly, my approach contrasts with a number of grounded theory studies, methodological statements, and research texts [see, e.g., @chenitz1986; @glaser1992; @martin1986; @strauss1990; @turner1981].
> By adopting a constructivist grounded theory approach, the researcher can move grounded theory methods further into the realm of interpretive social science consistent with a Blumerian [-@blumer1969] emphasis on meaning, without assuming the existence of a unidimensional external reality.
> A constructivist grounded theory recognizes the interactive nature of both data collection and analysis, resolves recent criticisms of the method, and reconciles positivist assumptions and postmodernist critiques.
> Moreover, a constructivist grounded theory fosters the development of qualitative traditions through the study of experience from the standpoint of those who live it.

Charmaz's [-@charmaz2000: 523] proposal for a re-visioned grounded theory poses research as a materializing process:

> A re-visioned grounded theory must take epistemological questions into account.
> Grounded theory can provide a path for researchers who want to continue to develop qualitative traditions without adopting the positivistic trappings of objectivism and universality.
> Hence the further development of a constructivist grounded theory can bridge past positivism and a revised future form of interpretive inquiry.
> A revised grounded theory preserves realism through gritty, empirical inquiry and sheds positivistic proclivities by becoming increasingly interpretive.

Charmaz [-@charmaz2000: 523] addresses realism and truth in constructivist grounded theory, and explicitly relates it to Blumerian situated interactionism:

> A constructivist grounded theory distinguishes between the real and the true.
> The constructivist approach does not seek truth --- single, universal, and lasting.
> Still, it remains realist because it addresses human _realities_ and assumes the existence of real worlds.
> However, neither human realities nor real worlds are unidimensional.
> We act within and upon our realities and worlds and thus develop dialectical relations among what we do, think, and feel.
> The constructivist approach assumes that what we take as real, as objective knowledge and truth, is based upon our perspective [@schwandt1994].
> The pragmatist underpinnings in symbolic interactionism emerge here.
> Thomas and Thomas [-@thomas1928: 572] proclaim, "If human beings define their situations as real, they are real in their consequences".
> Following their theorem, we must try to find what research participants define as real and where their definitions of reality take them.
> The constructivist approach also fosters our self-consciousness about what we attribute to our subjects and how, when, and why researchers portray these definitions as real.
> Thus the research products do not constitute the reality of the respondents' reality.
> Rather, each is a rendering, one interpretation among multiple interpretations, of a shared or individual reality.
> That interpretation is objectivist only to the extent that it seeks to construct analyses that show how respondents and the social scientists who study them construct those realities --- _without viewing those realities as unidimensional, universal, and immutable._
> Researchers' attention to detail in the constructivist approach sensitizes them to multiple realities and the multiple viewpoints within them; it does not represent a quest to capture a single reality.
> 
> Thus we can recast the obdurate character of social life that @blumer1969 talks about.
> In doing so, we change our conception of it from a real world to be discovered, tracked, and categorized to a world _made real_ in the minds and through the words and actions of its members.
> Thus the grounded theorist constructs an image of _a_ reality, not _the_ reality --- that is, objective, true, and external.

On the other hand, Charmaz [-@charmaz2000: 524] frames objectivist grounded theory as believing in some kind of truth:

> Objectivist grounded theory accepts the positivistic assumption of an external world that can be described, analyzed, explained, and predicted: truth, but with a small _t_.
> That is, objectivist grounded theory is modifiable as conditions change.
> It assumes that different observers will discover this world and describe it in similar ways
>  That's correct --- to the extent that subjects have comparable experiences (e.g., people with different chronic illnesses may experience uncertainty, intrusive regimens, medical dominance) and viewers bring similar que-tions, perspectives, methods, and, subsequently, concepts to analyze those experiences.
> Objectivist grounded theorists often share assumptions with their research participants --- particularly the professional participants.
> Perhaps more likely, they assume that respondents share their meanings.
> For example, Strauss and Corbin's [-@strauss1990] discussion of independence and dependence assumes that these terms hold the same meanings for patients as for researchers.

Charmaz [-@charmaz2000: 525] further embeds construvist grounded theory as a way to fulfill Blumer's symbolic interactionism:

> What helps researchers develop a constructivist grounded theory?
> How might they shape the data collection and analysis phases?
> Gaining depth and understanding in their work means that they can fulfill Blumer's [-@blumer1969] call for "intimate familiarity" with respondents and their worlds [see also @lofland1984; @lofland1995].
> In short, constructing constructivism means seeking meanings --- both respondents' meanings and researchers' meanings.

Charmaz [-@charmaz2000: 524] on the concretization of procedures from what were orginally meant to be guidelines:

> Guidelines such as those offered by @strauss1990 structure objectivist grounded theorists' work.
> These guidelines are didactic and prescriptive rather than emergent and interactive.
> Sanders [-@sanders1995: 92] refers to grounded theory procedures as "more rigorous than thou instructions about how information should be pressed into a mold".
> Strauss and Corbin categorize steps in the process with scientific terms such as axial coding and conditional matrix [@strauss1987; @strauss1990; @strauss1994].
> As grounded theory methods become more articulated, categorized, and elaborated, they seem to take on a life of their own.
> Guidelines turn into procedures and are reified into immutable rules, unlike Glaser and Strauss's [-@glaser1967] original flexible strategies.
> By taking grounded theory methods as prescriptive scientific rules, proponents further the positivist cast to obiectivist grounded theory.

##### On the modes of reasoning behind grounded theory

@kelle2005 is an overview of the Glaser / Strauss and Corbin split.
References to @kelle2005 have no page numbers since it is published in an online-only journal and does not specify paragraph numbers.

Highlights a primary impetus behind @glaser1967, which used political analogies to distinguish between "theoretical capitalists" and "proletariat testers", and unify the field of sociology by de-centering emphasis on theories developed by "great men".

A common thread in this paper is sensitivity to the practical challenges of actually doing grounded theory according to Glaser's approach:

> The infeasibility of an inductivist research strategy which demands an empty head (instead of an "open mind") cannot only be shown by epistemological arguments, it can also be seen in research practice.
> Especially novices in qualitative research with the strong desire to adhere to what they see as a basic principle and hallmark of Grounded Theory --- the "emergence" of categories from the data --- often experience a certain difficulty: in open coding the search for adequate coding categories can become extremely tedious and a subject of sometimes numerous and endless team sessions, especially if one hesitates to explicitly introduce theoretical knowledge.
> The declared purpose to let codes emerge from the data then leads to an enduring proliferation of the number of coding categories which makes the whole process insurmountable.

@kelle2005 basically takes down the original @glaser1967 and subsequent reflection on theoretecal sensitivity [@glaser1978].
He highlights fundamental contraditions and oversights with regards to the role of theory in grounded theory, specifically with regards to the notion that such research can be accomplished with inductive purity:

> Consequently, in the most early version of Grounded Theory the advice to employ theoretical sensitivity to identify theoretical relevant phenomena coexists with the idea that theoretical concepts "emerge" from the data if researchers approach the empirical field with no preconceived theories or hypotheses.
> Both ideas which have conflicting implications are not integrated with each other in the Discovery book.
> Furthermore, the concept of theoretical sensitivity is not converted into clear cut methodological rules: it remains unclear how a theoretically sensitive researcher can use previous theoretical knowledge to avoid drowning in the data.
> If one takes into account the frequent warnings not to force theoretical concepts on the data one gets the impression that a grounded theorist is advised to introduce suitable theoretical concepts ad hoc drawing on implicit theoretical knowledge but should abstain from approaching the empirical data with ex ante formulated hypotheses.

@kelle2005 recognizes that Glaser identified a series of "theoretical families" to help assist with the practical experience of coding.
I find it somewhat interesting that many of the terms in these first families are very reminiscient of so-called "natural language", as used in the wave of cybernets that was contemporary with @glaser1978 and which largely dealt with "expert systems".


> In the book "Theoretical Sensitivity" (1978) GLASER presents an extended list of terms which can be used for the purpose of theoretical coding loosely structured in the form of so called theoretical "coding families".
> Thereby various theoretical concepts stemming from different (sociological, philosophical or everyday) contexts are lumped together, as for example:
> 
> - terms, which relate to the degree of an attribute or property ("degree family"), like "limit", "range", "extent", "amount" etc.,
> - terms, which refer to the relation between a whole and its elements ("dimension family"), like "element", "part", "facet", "slice", "sector", "aspect", "segment" etc.,
> - terms, which refer to cultural phenomena ("cultural family") like "social norms", "social values", "social beliefs" etc.

This is substantiated by other observations by @kelle2005 that ad hoc coding actually follows _implicit_ theoretical knowledge:

> One of the most crucial differences between GLASER's and STRAUSS' approaches of Grounded Theory lies in the fact that STRAUSS and CORBIN propose the utilization of a specified theoretical framework based on a certain understanding of human action, whereas GLASER emphasises that coding as a process of combining "the analyst's scholarly knowledge and his research knowledge of the substantive field" (1978, p.70) has to be realised ad hoc, which means that it has often to be conducted on the basis of a more or less implicit theoretical background knowledge.

and that the Glaserian approach is better suited for more experienced, rather than novice sociologists, who will have internalized the theory that they then apply in their coding.


Kelle then goes on to address how grounded theory can or can not be applied in alignment with inductivist or hypothetic-deductivist reasoning, and raises abductive reasoning an an alternative means of arriving at legitimate and verifiable conclusions.
There is too much detail in the paper to copy here.

But here is another  nice conclusive gem from the end:

> Whereas STRAUSS and CORBIN pay a lot of attention to the question how grounded categories and propositions can be further validated, GLASER's concept shows at least a gleam of epistemological fundamentalism (or "certism", LAKATOS 1978) especially in his defence of the inductivism of early Grounded Theory.
> "Grounded theory looks for what is, not what might be, and therefore needs no test" (GLASER 1992, p.67).
> Such sentences carry the outmoded idea that empirical research can lead to final certainties and truths and that by using an inductive method the researcher may gain the ability to conceive "facts as they are" making any attempt of further corroboration futile.


##### Rebuttals by Glaser
@glaser2002 constitutes a rebuttal to @charmaz2000.
As @bryant2003 points out in his response to @glaser2002, it is very angry, polemical and irrational.
I don't want to go too in depth with the fundamental problems with Glaser's response (see Bryant's paper for the details), but the gist is that Glaser never really got the message about data being inherently constructed by researchers decisions, actions and circumstances.
Glaser seems to continue believing in the inherent neutrality of data as a matter of faith.

This being said, @glaser2002 did highlight the large emphasis on descriptive rather than explanatory potential in Charmaz's approach.
This aligns with my own apprehensions when I try to address the relevance of my work.
I tend to use the term "articulate" as a way to frame my work as descriptive, but in a way that lends value, and this very fuzzy distinction between the power of identying the shapes and relationships among things and explaining their causes and effects in a generalizable way (i.e., theories, or explanations), still somehow troubles me.
I wonder if Glaser is drawing a false distinction here, and through that, a false prioritization of explanation over description as a desired outcome.
This would put my mind at ease, as would dismissing Glaser's dismissal of people who simply don't know how to do the "real" grounded theory (which, in his mind, include all feminist and critical researchers).

##### On the _utility_ of grounded theory
I completely agree with this statement from Clarke [-@clarke2003: 555]:

> To address the needs and desires for empirical understandings of the complex and heterogeneous worlds emerging through new world orderings, new methods are requisite (Haraway 1999).
> I believe some such methods should be epistemologically/ ontologically based in the pragmatist soil that has historically nurtured symbolic interactionism and grounded theory.
> Through Mead, an interactionist grounded theory has always had the capacity to be distinctly perspectival in ways fully com patible with what are now understood as situated knowledges.
> This fundamental and always already postmodern edge of a grounded theory founded in symbolic interactionism makes it worth renovating.

This is super interesting, and really contextualizes how Strauss imagined grounded theory to be _useful_ for him:

> Some years ago, Katovich and Reese (1993:400–405) interestingly argued that Strauss’s negotiated order and related work recuperatively pulled the social around the postmodern turn through its methodological [grounded theoretical] recognition of the partial, tenuous, shifting, and unstable nature of the empirical world and its constructedness.
> I strongly agree and would argue that **Strauss also furthered this "postmodernization of the social" through his conceptualizations of social worlds and arenas as modes of understanding the deeply situated yet always also fluid orga nizational elements of negotiations.**
> He foreshadowed what later came to be known as postmodern assumptions: the instability of situations; characteristic changing, porous boundaries of both social worlds and arenas; social worlds seen as mutually constitutive/coproduced through negotiations taking place in arenas; negotiations as central social processes hailing that "things can always be otherwise"; and so on.
> Significantly, negotiations constitute discourses that also signal micropolitics of power as well as "the usual" meso/macrostructural elements—power in its more fluid forms (e.g., Foucault 1979, 1980).
> Through integrating the social worlds/arenas/ negotiations framework with grounded theory as a new conceptual infrastructure, I hope to sustain and extend the methodological contribution of grounded theory to understanding and elaborating what has been meant by "the social" in social life --- before, during, and after the postmodern turn.

It also echoes Charmaz's vision of grounded theory as a powerful too, and Bryant's [-@bryant2003] call to "look at what Glaser and Strauss actually did, rather than what they claimed --- and continued to claim --- they were doing" to uncover "the basis for a powerful research approach".
@bryant2003 further cites @baszanger1997, who characterize grounded theory as a method "consisting of accumulating a series of individual cases, of analyzing them as a combination between different logics of action that coexist not only in the field under consideration, but even within these individuals or during their encounters".
@bryant2003 summarizes this by stating that "[t]he aim of such methods is generalization rather than totalization, with the objective of producing "a combinative inventory of possible situations".

#### Theoretical sampling
See @charmaz2000: 519-520.

From Clarke [-@clarke2003: 557]:

> Unique to this approach has been, first, its requiring that analysis begin as soon as there are data. Coding begins immediately, and theorizing based on that coding does as well, however provisionally (Glaser 1978). Second, “sampling” is driven not necessarily (or not only) by attempts to be “representative” of some social body or population (or its heterogeneities) but especially and explicitly by theoretical con cerns that have emerged in the provisional analysis. Such “theoretical sampling” focuses on finding new data sources (persons or things) that can best explicitly ad dress specific theoretically interesting facets of the emergent analysis. Theoretical sampling has been integral to grounded theory from the outset, remains a fundamen tal strength of this analytic approach, and is crucial for the new situational analyses.


## Data Collection
### Interviews
See [@yin2014: 110-113]
See @becker1998

From Charmaz [-@charmaz2000: 525]:

> A constructivist approach necessitates a relationship with respondents in which they can cast their stories in their terms.
> It means listening to their stories with openness to feeling and experience.
> ...
> Furthermore, one-shot interviewing lends itself to a partial, sanitized view of experience, cleaned up for public discourse.
> The very structure of an interview may preclude private thoughts and feelings from emerging.
> Such a structure reinforces whatever proclivities a respondent has to tell only the public version of the story.
> Researchers' sustained involvement with research participants lessens these problems.

@fontana2000 spend some time writing about the emergence of an "interview society", whereby interviews are commonly used to seek various forms of biographical information.
They cite @holstein1998, who noted that "the interview has become a means of contemporary storytelling, where persons divulge life accounts in response to interview inquiries".
They then go over a brief history of interviewing in the context of sociological research, which largely tracks the values underlying positivist and postmodernist transitions as you might expect.

#### Structured interviewing
From Fontana and Frey [-@fontana2000: 649-651]:

Interviewers ask respondents a series of preestablished questions with a limited set of response categories.
The interview records responses according to a preestablished coding scheme.

Instructions to interviewers often follow these guidelines:

- Never get involved in long explanations of the study; use the standard explanation provided by the supervisor.
- Never deviate from the study introduction, sequence of questions, or question wording.
- Never let another person interrupt the interview; do not let another person answer for the respondent or offer his or her opinions on the question.
- Never suggest an answer or agree or disagree with an answer. Do not give the respondent any idea of your personal views on the topic of the question or the survey.
- Never interpret the meaning of a question; just repeat the question and give instructions or clarifications that are provided in training or by the supervisors.
- Never improvise, such as by assing answer categories or making wording changes.

The interviewer must establish a "balanced rapport", being casual and friendly while also directive and impersonal.
Interviewers must also perfect a style of "interested listening" that rewards respondents' participation but does not evaluate their responses.

From Fontana and Frey [-@fontana2000: 651]:

> This kind of interview often elicits rational responses, but it overlooks or inadequately assesses the emotional dimension.

#### Group interviews
From Fontana and Frey [-@fontana2000: 651-652]:

Can be used to test a methodological technique, try out a definition of a research problem or to identify key informants.
Pre-testing a questionnaire or survey design.

Can be used to aid respondents' recall of specific events or to stimulate embellished descriptions of events, or experiences shared by members of a group.

In formal group interviews, participants share views through the coordinator.

Less formal group interviews are meant to establish the widest range of meaning and interpretation on a topic, and the objective is "to tap intersubjective meaning with depth and diversity".

#### Unstructured interviewing
From Fontana and Frey [-@fontana2000: 652-657]:

The essence of an unstructured interview is establishing a human-to-human relation with the respondent and a desire to _understand_ rather than to _explain_.

@fontana then goes on with some practical guidance on how to engage in unstructured interviews, largely concerned with how to access a community and relate with respondents.

#### Transcribing
This section describes how I transcibe interviews and accounts for the decisions to encode certain things and not others.
It goes on to explains the procedures for transcribing spoken dialog into textual formats, including the notation applied to encode idiosyncratic elements of conversational speech.

Check out @silverman2000, who writes about the nuanced challenges of working with and between verbal and textual media, and what this means for transcription.

##### Transcript notation
Derived from the [transcription protocol applied for the E-CURATORS project](https://zackbatist.info/notes/E-CURATORS/#transcription).

##### Cleaning audio
To clean the audio:

1. I select a clip that is representative of a single source of background noise, and then filter that wavelength throughout the entire audio file.
2. After selecting the clip, go to `Effect >> Noise Reduction` and select `Get Noise Profile`, then press `OK`.
3. Close the noise reduction menu, select the entire range of audio using the keyboard shortcut `Command + A`.
4. Then go back to the noise reduction window (`Effect >> Noise Reduction`) to apply the filter based on the noise profile identified for the noisy clip.
5. Export the modified audio file to the working directory (`File >> Export >> Export as .WAV`).
6. Use `ffmpeg` to replace the dirty audio track with the clean one:

```bash
  ffmpeg -i dirty.mp4 -i clean.wav -c:v copy -map 0:v:0 -map 1:a:0 clean.mp4
```


### Observations
See @angrosino2000

### Field notes
See [@yin2014: 124-125]

### Recording video

## QDA
My QDA processes are most influenced by Kathy Charmaz and Johnny Saldaña, as well as the practical experiences instilled during my PhD and while working on E-CURATORS.

#### Sensitizing concepts
From @kelle2005:

> Herbert BLUMER invented the term "sensitizing concepts" to describe theoretical terms which "lack precise reference and have no bench marks which allow a clean cut identification of a specific instance" (1954, p.7). Sensitizing concepts are useful tools for descriptions but not for predictions, since their lack of empirical content permits researchers to apply them to a wide array of phenomena. Regardless how empirically contentless and vague they are, they may serve as heuristic tools for the construction of empirically grounded theories.

See @bowen2006

### Coding
These notes are largely derived from my reading of @saldana2016, provides a practical overview of what coding entails and specific methods and techniques.

Coding as component of knowledge construction:

- Coding is an intermediate step, "the "critical link" between data collection and their explanation or meaning" (@charmaz2001, as quoted in @saldana2016: 4)
- "coding is usually a mixture of data [summation] and data complication ... breaking the data apart in analytically relevant ways in order to ead toward further questions about the data" (@coffey1996: 29-31, as quoted and edited by @saldana2016: 9)
  - This relates to the paired notions of decodng when we reflect on a passage to decipher its core meaning, and encoding when we determine its appropriate code and label it [@saldana2016: 5].
- Coding "generates the bones of your analysis. ... [I]ntegration will assemble those bones into a working skeleton" (@charmaz2014: 113, quoted in @saldana2016: 9)
- To codify is to arrange things in a systematic order, to make something part of a system or classification, to categorize
  - What I sometimes refer to as arranging the code tree
  - What @saldana2016 refers to as categories, I tend to refer to as stubs
- Categories are arranged into themes or concepts, which in turn lead to assertions or theories

Pre-coding techniques:
- Data layout
  - Separation between lines or paragraphs may hold significant meaning
  - Putting interviewer words in square brackets or capital letters
- Semantic markup
  - Bold, italics, underline, highlight
  - Meant to identify "codable moments" worthy of attention (@boyatzis1998, as referenced in @saldana2016: 20)
  - Relates to @saldana2016: 22's prompt: "what strikes you?"
- Preliminary jottings
  - Tri-column exercise with the text on the left, first impression or preliminary code in the middle, and code on the right, after @liamputtong2005: 270-273.


Asking questions back to the interviewer, or participating in an imagined dialogue.
I imagine this might be useful in situations where the time to hold an interview is quite limited and I have to work with limited responses that don't touch on everything I want to cover.
The form of questions maintains my tentativity, my unwillingness to commit or assume their responses, and opens the door for their own responses in rebuttal.

Magnitude coding can be applied to tag positive/negative attitudes, but also other gradients like hard/soft, technical/social skills.
May be useful to apply symbols using my little 12-button keypad.

Can also use colons to identify a magnitude associated with a code's usage, as per 88-89.

Note: create a qc issue for sub-documents, for identifying sections of a document that are especially relevant and hiding less relevant sections.
I don't necessarily want to delete these lines, but I may want to hide them from view.
Maybe this is possible using vscode, outside of qc (see https://stackoverflow.com/a/72954133).


In lieu of initial/open coding, I think I will opt to devise sensitizing concepts, which may amalgamate as memos.
I could use the prefix "SC:" to denote sensitizing concepts.

What saldana refers to as "concept coding" is what I have previously referred to as "theoretical coding" to a certain extent.
It's a form of lumping, identifying specific instances under the label of cohesive concepts.


From Clarke [-@clarke2003: 558] on process coding:

> In a traditional grounded theory study, the key or basic social process is typically articulated in gerund form connoting ongoing action at an abstract level. Around this basic process are then constellated the particular and distinctive conditions, strategies, actions, and practices engaged in by human and nonhuman actors in volved with/in the process and their consequences. For example, subprocesses of disciplining the scientific study of reproduction include formalizing a scientific disci pline, gleaning fiscal support for research, producing contraceptives and other techno scientific products, and handling any social controversies the science provokes (such as cloning and stem cell research).

### Memos
Saldana chapter 2 on "analytic memos"

### Preliminary analyses
Yin [-@yin2014: 135-136 5] identifies various strategies for analyzing case study evidence.

> A helpful starting point is to "play" with your data.
> You are searching for patterns, insights, or concepts that seem promising.
> [@yin2014: 135]

Citing @miles1994, @yin2014 lists a few strategies at this playful stage:

- Juxtaposing data from different interviews
- Putting information into different arrays
- Making a matrix of categories and placing the evidence within them
- Tabulating the frequency of different events
- Putting information in chronological order or using some other temporal scheme

Yin [-@yin2014: 135] also emphasizes memo-writing as a core strategy at this stage, citing @corbin2014.
These memos should include hints, clues and suggestions that simply put into writing any preliminary interpretation, essentially conceptualizing your data.
He uses the specific example of shower thoughts.

### Analytical strategies and techniques
Yin [-@yin2014: 136-142] then goes on to describe four general strategies:

1. Relying on theoretical propositions
2. Working your data from the "ground up"
3. Developing a case description
4. Examining plausible rival explanations

Yin [-@yin2014: 142-168] then goes on to describe five analytical techniques:^[I wonder: would @abbott2004 call these heuristics?]

1. Pattern matching
2. Explanation building
3. Time-series analysis
4. Logic models
5. Cross-case synthesis


@ryan2000 describe various analysis techniques for analyzing textual elicitations in structured and codified ways.

### The constant comparative method
The constant comparative method is based on action codes, similar to what @saldana2016 refers to as process codes.
According to Charmaz [-@charmaz2000: 515]:
> The constant comparative method of grounded theory means (a) comparing different people (such as their views, situations, actions, accounts, and experiences), (b) comparing data from the same individuals with themselves at different points in time, (c) comparing incident with incident, (d) comparing data with categori, and (e) comparing categories with other categories.

My initial impression is that this is very well suited for Stake's [-@stake2006] multicase study framework, specifically with regards to his notion of the case-quintain dilemma.
It also seems very well suited for analysis of situational meaning-making, as per @suchman1987, @lave1991, @knorrcetina2001 and symbolic interactionism at large.

### Situational analysis
Situational analysis originates from Strauss's social worlds/arenas/negotiations framework.
From Clarke [-@clarke2003: 554]:

> Building on and extending Strauss’s work, situational analyses offer three main cartographic approaches:
> 
> 1. situational maps that lay out the major human, nonhuman, discursive, and other elements in the research situation of concern and provoke analyses of relations among them;
> 2. social worlds/arenas maps that lay out the collective actors, key nonhuman elements, and the arena(s) of commitment within which they are engaged in ongoing negotiations, or mesolevel interpretations of the situation; and
> 3. positional maps that lay out the major positions taken, and not taken, in the data vis-à-vis particular discursive axes of variation and difference, con cern, and controversy surrounding complicated issues in the situation.

Refer to highlighted sections in @clarke2003, bring those over at some point.

@clarke2003 refers to @shim2000 as an exemplary case of situational analysis in action.

### Statistical methods
crosstab

### On software
@weitzman2000 provides an overview of software and qualitative research, including a minihistory up to the year 2000 when the chapter was published.

Describing the first programs specifically designed for analysis of qualitative data, Weitzman [-@weitzman2000: 804] writes:

> Early programs like QUALOG and the first versions of NUDIST reflected the state of computing at that time.
> Researchers typically accomplished the coding of texts (tagging chunks of texts with labels --- codes --- that indicate the conceptual categories the researcher wants to sort them into) by typing in line numbers and code names at a command prompt, and there was little or no facility for memoing or other annotation or markup of text.^[This caught my eye since its the same approach as that adopted by [qc](https://qualitative-coding.readthedocs.io/en/latest/)!]
> In comparison with marking up text with coloured pencils, this felt awkward to many researchers.
> And computer support for the analysis of video or audio data was at best a fantasy.

This history if followed by a sober account of what software can and can not do in qualitative research, as well as affirmation and dismissed of hopes and fears.
Very reminiscient of @huggett2018.

## Writing
See @richardson2000, who frames writing as a method of inquiry.

See @mitchell1996

See Charmaz [-@charmaz2000: 526-528]


