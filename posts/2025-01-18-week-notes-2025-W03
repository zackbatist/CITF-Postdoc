---
title: Week notes (2025-W03)
date: 2025-01-18
categories:
  - week notes
---

I'm trying out a new way to track and communicate my progress on this project.
Every week I'll write a post to track the work I've been doing and reflect on my activities.
I'll try to maintain this document throughout the week, tidy it up and post it here on Friday afternoons.
However the specific process will probably vary as it grows into the rest of my workflow.

I'm purposefully trying to **not** tie this into the personal knowledge management trend.
It's for me and my own purposes, and I don't want to get bogged down with the unabashed managerial phoniness that belies the PKM phenomenon.

Anyway, I didn't take notes on my work this past week, but here's an overview of what I've done from memory:

Continued to take [notes on readings produced by the Maelstrom Project and its partners](../notes/maelstrom-readings.qmd).

Continued to investigate and maintain [notes on potential cases](../notes/potential-cases.qmd).

Set up a placeholder document for [notes on methodological concerns](../notes/methodology-notes.qmd).

Met with David for our bi-weekly check-in (meeting notes are private, at least for now).
I was also given access to the lab's private git server but haven't really had much of a chance to explore what it's being used for or devise my own plans to make use of it.

Worked extensively on the ethics protocol.
David and I went back and forth deciding on whether this was necessary, given how the project is based on his grant which already has IRB approval.
But it's better to play it safe than sorry, especially when it's necessary to obtain informed consent.
So to this end, I revised the research protocol and responses to the ethics form, and I also drafted an informed consent document.
I'll share all these things once the whole package is put together (probably in a week or two), but my responses to the ethics form already appears on the [ethics protocol](../ethics-protocol.qmd) page.


I simplified the way private documents are handled in the quarto project and git respository.
May still need to so some fiddling, especially for draft blog posts and notes.

I started drafting a blog post about the potential use of AI/LLMs in my research.
Stay tuned.

On a related note, I watched this recent [video about the use of LLMs in qualitative data analysis](https://www.youtube.com/watch?v=9nAFiF89D6o), which did not prompt me to draft the post but which is well-timed, nevertheless.

I worked a bit more on the [data management plan](../data-management.qmd), which prompted me to think more about which QDA software I'll use.
I started filling in a university form to use cloud services provided by MaxQDA, but stumbled upon [qualitative-coding](https://github.com/cproctor/qualitative-coding/) (abbreviated as qc), an open source CLI-based QDA system.
It represents a very innovative approach to QDA rooted in [computational thinking](https://www.cs.cmu.edu/link/research-notebook-computational-thinking-what-and-why) and [plain text social science](https://plain-text.co/), while also remaining true to the core tenets and purpose of QDA, [which make it unique and difficult to design software for](https://doi.org/10.46743/2160-3715/2018.3096).
If this is the sort of thing that appeals to you, I highly recommend you read the [docs](https://qualitative-coding.readthedocs.io/en/latest/).

I had a bit of trouble installing it and getting it running, but I met remotely with [Chris Proctor](https://chrisproctor.net/), who develops the tool through his work at the [Computational Literacies Lab](https://computationalliteracies.net/), based in the Department of Learning and Instruction at University at Buffalo (SUNY).
He helped me resolve some issues, gave me a guided tour of the system and we just talked about the overall state of qualitative data analysis and its tooling.
I don't really have the capacity right now to post everything he showed me but I will definitely be posting about my experiences tinkering around with qc in the coming weeks.

Similarly, [I asked on Mastodon](https://archaeo.social/@zackbatist/113821982780508126) about whether there are any tools that might support automatic generation of transcripts that include support for specialized notation.
A few linguists and conversation analysis scholars responded with recommendations to use [GailBot](https://sites.tufts.edu/hilab/gailbot/), and with discussion about the tool's capabilities and limitations.
I requested access to the software but haven't heard back from the dev team yet.
I also created a thread on the [whisper github repo](https://github.com/ggerganov/whisper.cpp/discussions/2732), which I now realize it a bit of a naive place to put it, and it hasn't yet gotten any responses.

I attended a talk from the epidemiology seminar series, which went wayyyy over my head.

Did my usual amount of engagement on masotodon, I suppose.
And I continued to make new friends in the department too :)

